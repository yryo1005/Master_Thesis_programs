{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- イラスト画像を学習に用いない\n",
    "- 文字が含まれる画像を学習に用いない\n",
    "- 固有名詞を含む大喜利を学習に用いない\n",
    "- 大喜利の最小の星の数: 0\n",
    "- 単語の最小出現回数: 32\n",
    "- 大喜利の最小単語数: 4\n",
    "- 大喜利の最大単語数: 31\n",
    "- 画像の高さ: 128\n",
    "- 画像の幅: 128\n",
    "- AMAEの特徴量次元数: 16384\n",
    "- AMAE EPOCH: 25\n",
    "- AMAE BATCH SIZE: 32\n",
    "- AMAE LEARNING RATE: 0.0001\n",
    "- AMAE ALPHA: 1.0\n",
    "- AMAE CHAIN: 3\n",
    "- EPOCH: 25\n",
    "- BATCH SIZE: 512\n",
    "- LEARNING RATE: 0.0001\n",
    "- FEATURE DIM: 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "result directory: ../../results/Augmix_Autoencoder/False_False_False_0_32_4_31_128_128_25_32_0.0001_16384_1.0_3_3/\n",
      "result directory: ../../results/GUMI_AMAE/False_False_False_0_32_4_31_128_128_25_32_0.0001_16384_1.0_3_3_25_512_0.0001_1024/\n",
      "  5%|█▊                                 | 33841/668982 [01:36<23:27, 451.28it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_workers = int(os.cpu_count() * 0.8)\n",
    "print(num_workers)\n",
    "\n",
    "!python train.py \\\n",
    "    --num_workers {num_workers} \\\n",
    "    --min_star 0 \\\n",
    "    --min_apper_word 32 \\\n",
    "    --min_sentence_length 4\\\n",
    "    --max_sentence_length 31 \\\n",
    "    --image_height 128 \\\n",
    "    --image_width 128 \\\n",
    "    --amae_feature_dim 16384 \\\n",
    "    --amae_epoch 25 \\\n",
    "    --amae_batch_size 32 \\\n",
    "    --amae_learning_rate 0.0001 \\\n",
    "    --amae_alpha 1.0 \\\n",
    "    --amae_chain 3 \\\n",
    "    --amae_depth 3 \\\n",
    "    --epoch 25 \\\n",
    "    --batch_size 512 \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --feature_dim 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- イラスト画像を学習に用いない\n",
    "- 文字が含まれる画像を学習に用いない\n",
    "- 固有名詞を含む大喜利を学習に用いない\n",
    "- 大喜利の最小の星の数: 0\n",
    "- 単語の最小出現回数: 32\n",
    "- 大喜利の最小単語数: 4\n",
    "- 大喜利の最大単語数: 31\n",
    "- 画像の高さ: 128\n",
    "- 画像の幅: 128\n",
    "- AMAEの特徴量次元数: 16384\n",
    "- AMAE EPOCH: 25\n",
    "- AMAE BATCH SIZE: 32\n",
    "- AMAE LEARNING RATE: 0.0001\n",
    "- AMAE ALPHA: **10.0**\n",
    "- AMAE CHAIN: 3\n",
    "- EPOCH: 25\n",
    "- BATCH SIZE: 512\n",
    "- LEARNING RATE: 0.0001\n",
    "- FEATURE DIM: 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Cloning into 'Japanese_BPEEncoder_V2'...\n",
      "remote: Enumerating objects: 43, done.\u001b[K\n",
      "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 43 (delta 24), reused 35 (delta 16), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (43/43), 1.14 MiB | 34.36 MiB/s, done.\n",
      "Resolving deltas: 100% (24/24), done.\n",
      "result directory: ../../results/Augmix_Autoencoder/False_False_False_0_32_4_31_128_128_25_32_0.0001_16384_10.0_3_3/\n",
      "result directory: ../../results/GUMI_AMAE/False_False_False_0_32_4_31_128_128_25_32_0.0001_16384_10.0_3_3_25_512_0.0001_1024/\n",
      "100%|█████████████████████████████████| 668982/668982 [02:35<00:00, 4295.74it/s]\n",
      "AMAEの学習に用いる画像の数: 228908\n",
      " AmAEの検証に用いる画像の数: 25435\n",
      "\n",
      "num data: 228908\n",
      "num data: 25435\n",
      "Epoch 1/25: 100%|████████| 7154/7154 [23:58<00:00,  4.97it/s, train_loss=0.0727]\n",
      "Epoch 1/25: 100%|███████████| 795/795 [00:31<00:00, 25.07it/s, test_loss=0.0536]\n",
      "Epoch: 1/25, Train Loss: 0.0727, Test Loss: 0.0536\n",
      "-------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/workspace/Master_Thesis/Master_Thesis_programs/GUMI_AMAE/train.py\", line 556, in <module>\n",
      "    predict_by_augmix_autoencoder(augmix_autoencoder, test_image_paths[:5], chain = AMAE_CHAIN, max_depth = AMAE_DEPTH)\n",
      "  File \"/home/user/workspace/Master_Thesis/Master_Thesis_programs/GUMI_AMAE/train.py\", line 423, in predict_by_augmix_autoencoder\n",
      "    tmp_images = [image_preprocess(I) for I in tmp_images] + [ image_preprocess( augmix_operation(I, chain = chain, max_depth = max_depth) / 255.0 ) for I in tmp_images ]\n",
      "  File \"/home/user/workspace/Master_Thesis/Master_Thesis_programs/GUMI_AMAE/train.py\", line 423, in <listcomp>\n",
      "    tmp_images = [image_preprocess(I) for I in tmp_images] + [ image_preprocess( augmix_operation(I, chain = chain, max_depth = max_depth) / 255.0 ) for I in tmp_images ]\n",
      "  File \"/home/user/workspace/Master_Thesis/Master_Thesis_programs/GUMI_AMAE/train.py\", line 283, in augmix_operation\n",
      "    mixed_img += W * img\n",
      "ValueError: operands could not be broadcast together with shapes (128,128,3) (128,128) (128,128,3) \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_workers = int(os.cpu_count() * 0.8)\n",
    "print(num_workers)\n",
    "\n",
    "!python train.py \\\n",
    "    --num_workers {num_workers} \\\n",
    "    --min_star 0 \\\n",
    "    --min_apper_word 32 \\\n",
    "    --min_sentence_length 4\\\n",
    "    --max_sentence_length 31 \\\n",
    "    --image_height 128 \\\n",
    "    --image_width 128 \\\n",
    "    --amae_feature_dim 16384 \\\n",
    "    --amae_epoch 25 \\\n",
    "    --amae_batch_size 32 \\\n",
    "    --amae_learning_rate 0.0001 \\\n",
    "    --amae_alpha 10.0 \\\n",
    "    --amae_chain 3 \\\n",
    "    --amae_depth 3 \\\n",
    "    --epoch 25 \\\n",
    "    --batch_size 512 \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --feature_dim 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- イラスト画像を学習に用いない\n",
    "- 文字が含まれる画像を学習に用いない\n",
    "- 固有名詞を含む大喜利を学習に用いない\n",
    "- 大喜利の最小の星の数: 0\n",
    "- 単語の最小出現回数: 32\n",
    "- 大喜利の最小単語数: 4\n",
    "- 大喜利の最大単語数: 31\n",
    "- 画像の高さ: 128\n",
    "- 画像の幅: 128\n",
    "- AMAEの特徴量次元数: 16384\n",
    "- AMAE EPOCH: 25\n",
    "- AMAE BATCH SIZE: 32\n",
    "- AMAE LEARNING RATE: 0.0001\n",
    "- AMAE ALPHA: **100.0**\n",
    "- AMAE CHAIN: 3\n",
    "- EPOCH: 25\n",
    "- BATCH SIZE: 512\n",
    "- LEARNING RATE: 0.0001\n",
    "- FEATURE DIM: 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "result directory: ../../results/Augmix_Autoencoder/False_False_False_0_32_4_31_128_128_25_32_0.0001_16384_100.0_3_3/\n",
      "result directory: ../../results/GUMI_AMAE/False_False_False_0_32_4_31_128_128_25_32_0.0001_16384_100.0_3_3_25_512_0.0001_1024/\n",
      "100%|█████████████████████████████████| 668982/668982 [02:16<00:00, 4896.62it/s]\n",
      "AMAEの学習に用いる画像の数: 228908\n",
      " AmAEの検証に用いる画像の数: 25435\n",
      "\n",
      "num data: 228908\n",
      "num data: 25435\n",
      "Epoch 1/25: 100%|████████| 7154/7154 [24:23<00:00,  4.89it/s, train_loss=0.0734]\n",
      "Epoch 1/25: 100%|████████████| 795/795 [00:31<00:00, 25.12it/s, test_loss=0.054]\n",
      "Epoch: 1/25, Train Loss: 0.0734, Test Loss: 0.0538\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 2/25: 100%|████████| 7154/7154 [24:21<00:00,  4.90it/s, train_loss=0.0493]\n",
      "Epoch 2/25: 100%|███████████| 795/795 [00:31<00:00, 24.85it/s, test_loss=0.0462]\n",
      "Epoch: 2/25, Train Loss: 0.0493, Test Loss: 0.0460\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 3/25: 100%|████████| 7154/7154 [24:27<00:00,  4.88it/s, train_loss=0.0433]\n",
      "Epoch 3/25: 100%|███████████| 795/795 [00:31<00:00, 24.94it/s, test_loss=0.0427]\n",
      "Epoch: 3/25, Train Loss: 0.0433, Test Loss: 0.0427\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 4/25: 100%|████████| 7154/7154 [24:18<00:00,  4.90it/s, train_loss=0.0399]\n",
      "Epoch 4/25: 100%|███████████| 795/795 [00:31<00:00, 24.98it/s, test_loss=0.0388]\n",
      "Epoch: 4/25, Train Loss: 0.0399, Test Loss: 0.0388\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 5/25: 100%|████████| 7154/7154 [24:17<00:00,  4.91it/s, train_loss=0.0374]\n",
      "Epoch 5/25: 100%|████████████| 795/795 [00:31<00:00, 24.93it/s, test_loss=0.037]\n",
      "Epoch: 5/25, Train Loss: 0.0374, Test Loss: 0.0368\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 6/25: 100%|████████| 7154/7154 [24:19<00:00,  4.90it/s, train_loss=0.0356]\n",
      "Epoch 6/25: 100%|███████████| 795/795 [00:33<00:00, 24.05it/s, test_loss=0.0355]\n",
      "Epoch: 6/25, Train Loss: 0.0356, Test Loss: 0.0353\n",
      "-------------------------\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Figure(1500x500)\n",
      "Epoch 7/25: 100%|████████| 7154/7154 [24:20<00:00,  4.90it/s, train_loss=0.0341]\n",
      "Epoch 7/25: 100%|███████████| 795/795 [00:34<00:00, 23.22it/s, test_loss=0.0342]\n",
      "Epoch: 7/25, Train Loss: 0.0341, Test Loss: 0.0341\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 8/25: 100%|█████████| 7154/7154 [24:25<00:00,  4.88it/s, train_loss=0.033]\n",
      "Epoch 8/25: 100%|████████████| 795/795 [00:32<00:00, 24.34it/s, test_loss=0.033]\n",
      "Epoch: 8/25, Train Loss: 0.0330, Test Loss: 0.0330\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 9/25: 100%|████████| 7154/7154 [24:22<00:00,  4.89it/s, train_loss=0.0319]\n",
      "Epoch 9/25: 100%|████████████| 795/795 [00:34<00:00, 23.30it/s, test_loss=0.032]\n",
      "Epoch: 9/25, Train Loss: 0.0319, Test Loss: 0.0319\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 10/25: 100%|████████| 7154/7154 [24:26<00:00,  4.88it/s, train_loss=0.031]\n",
      "Epoch 10/25: 100%|██████████| 795/795 [00:31<00:00, 25.12it/s, test_loss=0.0313]\n",
      "Epoch: 10/25, Train Loss: 0.0310, Test Loss: 0.0312\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 11/25: 100%|███████| 7154/7154 [24:27<00:00,  4.88it/s, train_loss=0.0303]\n",
      "Epoch 11/25: 100%|██████████| 795/795 [00:31<00:00, 24.95it/s, test_loss=0.0309]\n",
      "Epoch: 11/25, Train Loss: 0.0303, Test Loss: 0.0309\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 12/25: 100%|███████| 7154/7154 [24:27<00:00,  4.87it/s, train_loss=0.0293]\n",
      "Epoch 12/25: 100%|██████████| 795/795 [00:32<00:00, 24.84it/s, test_loss=0.0293]\n",
      "Epoch: 12/25, Train Loss: 0.0293, Test Loss: 0.0292\n",
      "-------------------------\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Figure(1500x500)\n",
      "Epoch 13/25: 100%|███████| 7154/7154 [24:35<00:00,  4.85it/s, train_loss=0.0276]\n",
      "Epoch 13/25: 100%|███████████| 795/795 [00:33<00:00, 23.86it/s, test_loss=0.028]\n",
      "Epoch: 13/25, Train Loss: 0.0276, Test Loss: 0.0280\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 14/25: 100%|███████| 7154/7154 [24:38<00:00,  4.84it/s, train_loss=0.0267]\n",
      "Epoch 14/25: 100%|██████████| 795/795 [00:33<00:00, 23.61it/s, test_loss=0.0273]\n",
      "Epoch: 14/25, Train Loss: 0.0267, Test Loss: 0.0272\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 15/25: 100%|███████| 7154/7154 [24:31<00:00,  4.86it/s, train_loss=0.0261]\n",
      "Epoch 15/25: 100%|██████████| 795/795 [00:35<00:00, 22.50it/s, test_loss=0.0271]\n",
      "Epoch: 15/25, Train Loss: 0.0261, Test Loss: 0.0270\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 16/25: 100%|███████| 7154/7154 [24:40<00:00,  4.83it/s, train_loss=0.0256]\n",
      "Epoch 16/25: 100%|██████████| 795/795 [00:34<00:00, 22.74it/s, test_loss=0.0266]\n",
      "Epoch: 16/25, Train Loss: 0.0256, Test Loss: 0.0265\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 17/25: 100%|███████| 7154/7154 [24:30<00:00,  4.87it/s, train_loss=0.0251]\n",
      "Epoch 17/25: 100%|███████████| 795/795 [00:33<00:00, 23.63it/s, test_loss=0.026]\n",
      "Epoch: 17/25, Train Loss: 0.0251, Test Loss: 0.0260\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 18/25: 100%|███████| 7154/7154 [24:32<00:00,  4.86it/s, train_loss=0.0245]\n",
      "Epoch 18/25: 100%|██████████| 795/795 [00:32<00:00, 24.63it/s, test_loss=0.0259]\n",
      "Epoch: 18/25, Train Loss: 0.0245, Test Loss: 0.0259\n",
      "-------------------------\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Figure(1500x500)\n",
      "Epoch 19/25: 100%|████████| 7154/7154 [24:34<00:00,  4.85it/s, train_loss=0.024]\n",
      "Epoch 19/25: 100%|██████████| 795/795 [00:32<00:00, 24.49it/s, test_loss=0.0252]\n",
      "Epoch: 19/25, Train Loss: 0.0240, Test Loss: 0.0251\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 20/25: 100%|███████| 7154/7154 [24:32<00:00,  4.86it/s, train_loss=0.0236]\n",
      "Epoch 20/25: 100%|███████████| 795/795 [00:32<00:00, 24.53it/s, test_loss=0.025]\n",
      "Epoch: 20/25, Train Loss: 0.0236, Test Loss: 0.0250\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 21/25: 100%|███████| 7154/7154 [24:35<00:00,  4.85it/s, train_loss=0.0233]\n",
      "Epoch 21/25: 100%|███████████| 795/795 [00:32<00:00, 24.70it/s, test_loss=0.025]\n",
      "Epoch: 21/25, Train Loss: 0.0233, Test Loss: 0.0250\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 22/25: 100%|████████| 7154/7154 [24:33<00:00,  4.86it/s, train_loss=0.023]\n",
      "Epoch 22/25: 100%|███████████| 795/795 [00:33<00:00, 23.88it/s, test_loss=0.025]\n",
      "Epoch: 22/25, Train Loss: 0.0230, Test Loss: 0.0250\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 23/25: 100%|███████| 7154/7154 [24:33<00:00,  4.85it/s, train_loss=0.0226]\n",
      "Epoch 23/25: 100%|██████████| 795/795 [00:32<00:00, 24.50it/s, test_loss=0.0241]\n",
      "Epoch: 23/25, Train Loss: 0.0226, Test Loss: 0.0240\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 24/25: 100%|███████| 7154/7154 [24:34<00:00,  4.85it/s, train_loss=0.0221]\n",
      "Epoch 24/25: 100%|██████████| 795/795 [00:32<00:00, 24.51it/s, test_loss=0.0238]\n",
      "Epoch: 24/25, Train Loss: 0.0221, Test Loss: 0.0237\n",
      "-------------------------\n",
      "Figure(1500x500)\n",
      "Epoch 25/25: 100%|███████| 7154/7154 [24:35<00:00,  4.85it/s, train_loss=0.0218]\n",
      "Epoch 25/25: 100%|██████████| 795/795 [00:33<00:00, 24.00it/s, test_loss=0.0241]\n",
      "Epoch: 25/25, Train Loss: 0.0218, Test Loss: 0.0241\n",
      "-------------------------\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Figure(1500x500)\n",
      "100%|█████████████████████████████████| 668970/668970 [08:36<00:00, 1295.72it/s]\n",
      "100%|█████████████████████████████| 2135982/2135982 [00:03<00:00, 552745.41it/s]\n",
      "100%|█████████████████████████████| 2051435/2051435 [00:02<00:00, 722386.44it/s]\n",
      "学習に用いる大喜利の数: 2030920\n",
      " 検証に用いる大喜利の数: 20515\n",
      " 使用する画像の数: 244286\n",
      " 単語の種類: 16705\n",
      "100%|███████████████████████████████| 244286/244286 [00:00<00:00, 701144.46it/s]\n",
      "num data: 244286\n",
      "/home/user/workspace/Master_Thesis/Master_Thesis_programs/GUMI_AMAE/train.py:762: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  augmix_autoencoder.load_state_dict(torch.load(f\"{AMAE_RESULT_DIR}best_model.pth\"))\n",
      "100%|███████████████████████████████████████| 1909/1909 [01:13<00:00, 26.02it/s]\n",
      "100%|█████████████████████████████| 2030920/2030920 [00:07<00:00, 267196.56it/s]\n",
      "num data: 2030920\n",
      "100%|█████████████████████████████████| 20515/20515 [00:00<00:00, 522146.85it/s]\n",
      "num data: 20515\n",
      "Epoch 1/25: 100%|█| 3967/3967 [18:36<00:00,  3.55it/s, train_loss=4.97, train_ac\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.32it/s, test_loss=4.42, test_accuracy\n",
      "Epoch: 1/25, Train Loss: 4.9673, Train Accuracy: 0.2449, Test Loss: 4.4244, Test Accuracy: 0.2896\n",
      "-------------------------\n",
      "Epoch 2/25: 100%|█| 3967/3967 [18:38<00:00,  3.55it/s, train_loss=4.27, train_ac\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.34it/s, test_loss=4.17, test_accuracy\n",
      "Epoch: 2/25, Train Loss: 4.2683, Train Accuracy: 0.3023, Test Loss: 4.1692, Test Accuracy: 0.3115\n",
      "-------------------------\n",
      "Epoch 3/25: 100%|█| 3967/3967 [18:44<00:00,  3.53it/s, train_loss=4.05, train_ac\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.48it/s, test_loss=4.04, test_accuracy\n",
      "Epoch: 3/25, Train Loss: 4.0546, Train Accuracy: 0.3206, Test Loss: 4.0442, Test Accuracy: 0.3229\n",
      "-------------------------\n",
      "Epoch 4/25: 100%|█| 3967/3967 [18:45<00:00,  3.52it/s, train_loss=3.92, train_ac\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.38it/s, test_loss=3.97, test_accuracy\n",
      "Epoch: 4/25, Train Loss: 3.9177, Train Accuracy: 0.3324, Test Loss: 3.9719, Test Accuracy: 0.3300\n",
      "-------------------------\n",
      "Epoch 5/25: 100%|█| 3967/3967 [18:47<00:00,  3.52it/s, train_loss=3.81, train_ac\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.04it/s, test_loss=3.92, test_accuracy\n",
      "Epoch: 5/25, Train Loss: 3.8146, Train Accuracy: 0.3413, Test Loss: 3.9244, Test Accuracy: 0.3350\n",
      "-------------------------\n",
      "Epoch 6/25: 100%|█| 3967/3967 [18:51<00:00,  3.51it/s, train_loss=3.73, train_ac\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.16it/s, test_loss=3.89, test_accuracy\n",
      "Epoch: 6/25, Train Loss: 3.7299, Train Accuracy: 0.3486, Test Loss: 3.8923, Test Accuracy: 0.3388\n",
      "-------------------------\n",
      "Epoch 7/25: 100%|█| 3967/3967 [18:50<00:00,  3.51it/s, train_loss=3.66, train_ac\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.38it/s, test_loss=3.87, test_accuracy\n",
      "Epoch: 7/25, Train Loss: 3.6570, Train Accuracy: 0.3550, Test Loss: 3.8728, Test Accuracy: 0.3411\n",
      "-------------------------\n",
      "Epoch 8/25: 100%|█| 3967/3967 [18:52<00:00,  3.50it/s, train_loss=3.59, train_ac\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.26it/s, test_loss=3.86, test_accuracy\n",
      "Epoch: 8/25, Train Loss: 3.5921, Train Accuracy: 0.3607, Test Loss: 3.8629, Test Accuracy: 0.3426\n",
      "-------------------------\n",
      "Epoch 9/25: 100%|█| 3967/3967 [18:49<00:00,  3.51it/s, train_loss=3.53, train_ac\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.21it/s, test_loss=3.86, test_accuracy\n",
      "Epoch: 9/25, Train Loss: 3.5332, Train Accuracy: 0.3660, Test Loss: 3.8603, Test Accuracy: 0.3434\n",
      "-------------------------\n",
      "Epoch 10/25: 100%|█| 3967/3967 [18:48<00:00,  3.52it/s, train_loss=3.48, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.25it/s, test_loss=3.86, test_accuracy\n",
      "Epoch: 10/25, Train Loss: 3.4788, Train Accuracy: 0.3709, Test Loss: 3.8628, Test Accuracy: 0.3442\n",
      "-------------------------\n",
      "Epoch 11/25: 100%|█| 3967/3967 [18:48<00:00,  3.52it/s, train_loss=3.43, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.38it/s, test_loss=3.87, test_accuracy\n",
      "Epoch: 11/25, Train Loss: 3.4283, Train Accuracy: 0.3756, Test Loss: 3.8703, Test Accuracy: 0.3443\n",
      "-------------------------\n",
      "Epoch 12/25: 100%|█| 3967/3967 [18:50<00:00,  3.51it/s, train_loss=3.38, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.18it/s, test_loss=3.88, test_accuracy\n",
      "Epoch: 12/25, Train Loss: 3.3811, Train Accuracy: 0.3801, Test Loss: 3.8812, Test Accuracy: 0.3443\n",
      "-------------------------\n",
      "Epoch 13/25: 100%|█| 3967/3967 [18:49<00:00,  3.51it/s, train_loss=3.34, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.19it/s, test_loss=3.9, test_accuracy=\n",
      "Epoch: 13/25, Train Loss: 3.3366, Train Accuracy: 0.3846, Test Loss: 3.8958, Test Accuracy: 0.3442\n",
      "-------------------------\n",
      "Epoch 14/25: 100%|█| 3967/3967 [18:53<00:00,  3.50it/s, train_loss=3.29, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  5.90it/s, test_loss=3.91, test_accuracy\n",
      "Epoch: 14/25, Train Loss: 3.2946, Train Accuracy: 0.3889, Test Loss: 3.9120, Test Accuracy: 0.3439\n",
      "-------------------------\n",
      "Epoch 15/25: 100%|█| 3967/3967 [18:52<00:00,  3.50it/s, train_loss=3.25, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.26it/s, test_loss=3.93, test_accuracy\n",
      "Epoch: 15/25, Train Loss: 3.2550, Train Accuracy: 0.3931, Test Loss: 3.9308, Test Accuracy: 0.3433\n",
      "-------------------------\n",
      "Epoch 16/25: 100%|█| 3967/3967 [18:50<00:00,  3.51it/s, train_loss=3.22, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.30it/s, test_loss=3.95, test_accuracy\n",
      "Epoch: 16/25, Train Loss: 3.2175, Train Accuracy: 0.3973, Test Loss: 3.9505, Test Accuracy: 0.3429\n",
      "-------------------------\n",
      "Epoch 17/25: 100%|█| 3967/3967 [18:51<00:00,  3.51it/s, train_loss=3.18, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.06it/s, test_loss=3.97, test_accuracy\n",
      "Epoch: 17/25, Train Loss: 3.1820, Train Accuracy: 0.4014, Test Loss: 3.9721, Test Accuracy: 0.3423\n",
      "-------------------------\n",
      "Epoch 18/25: 100%|█| 3967/3967 [18:51<00:00,  3.51it/s, train_loss=3.15, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.29it/s, test_loss=4, test_accuracy=0.\n",
      "Epoch: 18/25, Train Loss: 3.1485, Train Accuracy: 0.4053, Test Loss: 3.9961, Test Accuracy: 0.3415\n",
      "-------------------------\n",
      "Epoch 19/25: 100%|█| 3967/3967 [18:53<00:00,  3.50it/s, train_loss=3.12, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.11it/s, test_loss=4.02, test_accuracy\n",
      "Epoch: 19/25, Train Loss: 3.1166, Train Accuracy: 0.4092, Test Loss: 4.0218, Test Accuracy: 0.3405\n",
      "-------------------------\n",
      "Epoch 20/25: 100%|█| 3967/3967 [18:52<00:00,  3.50it/s, train_loss=3.09, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.26it/s, test_loss=4.05, test_accuracy\n",
      "Epoch: 20/25, Train Loss: 3.0858, Train Accuracy: 0.4131, Test Loss: 4.0492, Test Accuracy: 0.3398\n",
      "-------------------------\n",
      "Epoch 21/25: 100%|█| 3967/3967 [18:52<00:00,  3.50it/s, train_loss=3.06, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.15it/s, test_loss=4.08, test_accuracy\n",
      "Epoch: 21/25, Train Loss: 3.0558, Train Accuracy: 0.4169, Test Loss: 4.0761, Test Accuracy: 0.3389\n",
      "-------------------------\n",
      "Epoch 22/25: 100%|█| 3967/3967 [18:51<00:00,  3.51it/s, train_loss=3.03, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.34it/s, test_loss=4.1, test_accuracy=\n",
      "Epoch: 22/25, Train Loss: 3.0267, Train Accuracy: 0.4208, Test Loss: 4.1024, Test Accuracy: 0.3382\n",
      "-------------------------\n",
      "Epoch 23/25: 100%|█| 3967/3967 [18:52<00:00,  3.50it/s, train_loss=3, train_accu\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.23it/s, test_loss=4.13, test_accuracy\n",
      "Epoch: 23/25, Train Loss: 2.9988, Train Accuracy: 0.4245, Test Loss: 4.1301, Test Accuracy: 0.3372\n",
      "-------------------------\n",
      "Epoch 24/25: 100%|█| 3967/3967 [18:51<00:00,  3.51it/s, train_loss=2.97, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:06<00:00,  6.26it/s, test_loss=4.16, test_accuracy\n",
      "Epoch: 24/25, Train Loss: 2.9723, Train Accuracy: 0.4282, Test Loss: 4.1577, Test Accuracy: 0.3363\n",
      "-------------------------\n",
      "Epoch 25/25: 100%|█| 3967/3967 [18:51<00:00,  3.51it/s, train_loss=2.95, train_a\n",
      "Evaluating: 100%|█| 41/41 [00:07<00:00,  5.83it/s, test_loss=4.19, test_accuracy\n",
      "Epoch: 25/25, Train Loss: 2.9477, Train Accuracy: 0.4316, Test Loss: 4.1890, Test Accuracy: 0.3356\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_workers = int(os.cpu_count() * 0.8)\n",
    "print(num_workers)\n",
    "\n",
    "!python train.py \\\n",
    "    --num_workers {num_workers} \\\n",
    "    --min_star 0 \\\n",
    "    --min_apper_word 32 \\\n",
    "    --min_sentence_length 4\\\n",
    "    --max_sentence_length 31 \\\n",
    "    --image_height 128 \\\n",
    "    --image_width 128 \\\n",
    "    --amae_feature_dim 16384 \\\n",
    "    --amae_epoch 25 \\\n",
    "    --amae_batch_size 32 \\\n",
    "    --amae_learning_rate 0.0001 \\\n",
    "    --amae_alpha 100.0 \\\n",
    "    --amae_chain 3 \\\n",
    "    --amae_depth 3 \\\n",
    "    --epoch 25 \\\n",
    "    --batch_size 512 \\\n",
    "    --learning_rate 0.0001 \\\n",
    "    --feature_dim 1024"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
