{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import subprocess\n",
    "if not os.path.exists(\"Japanese_BPEEncoder_V2\"):\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/tanreinama/Japanese-BPEEncoder_V2.git\", \"Japanese_BPEEncoder_V2\"])\n",
    "from Japanese_BPEEncoder_V2.encode_swe import SWEEncoder_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # コマンドライン引数の処理\n",
    "# parser = argparse.ArgumentParser(description=\"設定用プログラム\")\n",
    "\n",
    "# parser.add_argument(\"--num_workers\", type = int, default = 16, help = \"データローダが使用するCPUのスレッド数(GPUの総スレッド数の8割が推奨)\")\n",
    "# parser.add_argument(\"--reset_data\", action = \"store_true\", help = \"データセットを再作成するか\")\n",
    "# parser.add_argument(\"--retrain_autoencoder\", action = \"store_true\", help = \"Autoencoderを再学習するか\")\n",
    "# parser.add_argument(\"--use_unreal_image\", action = \"store_true\", help = \"現実写真以外を使用する\")\n",
    "# parser.add_argument(\"--use_word_image\", action = \"store_true\", help = \"文字を含む画像を使用する\")\n",
    "# parser.add_argument(\"--use_unique_noun_boke\", action = \"store_true\", help = \"固有名詞を含む大喜利を使用する\")\n",
    "# parser.add_argument(\"--min_star\", type = int, default = 0, help = \"大喜利の最小の星の数\")\n",
    "# parser.add_argument(\"--min_apper_word\", type = int, default = 32, help = \"単語の最小出現回数\")\n",
    "# parser.add_argument(\"--min_sentence_length\", type = int, default = 4, help = \"大喜利の最小単語数\")\n",
    "# parser.add_argument(\"--max_sentence_length\", type = int, default = 31, help = \"大喜利の最大単語数\")\n",
    "# parser.add_argument(\"--image_height\", type = int, default = 4, help = \"画像の高さ\")\n",
    "# parser.add_argument(\"--image_width\", type = int, default = 4, help = \"画像の幅\")\n",
    "# parser.add_argument(\"--ae_feature_dim\", type = int, default = 4, help = \"AEの特徴量次元数\")\n",
    "# parser.add_argument(\"--ae_epoch\", type = int, default = 25, help = \"AEの学習反復回数\")\n",
    "# parser.add_argument(\"--ae_batch_size\", type = int, default = 512, help = \"AEのバッチサイズ\")\n",
    "# parser.add_argument(\"--ae_learning_rate\", type = float, default = 0.001, help = \"AEの学習率\")\n",
    "# parser.add_argument(\"--epoch\", type = int, default = 25, help = \"学習反復回数\")\n",
    "# parser.add_argument(\"--batch_size\", type = int, default = 512, help = \"バッチサイズ\")\n",
    "# parser.add_argument(\"--learning_rate\", type = float, default = 0.001, help = \"学習率\")\n",
    "# parser.add_argument(\"--feature_dim\", type = int, default = 1024, help = \"モデルの特徴量次元数\")\n",
    "\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result directory: ../../results/Autoencoder/False_False_False_0_32_4_31_128_128_25_32_0.0001_16384/\n",
      "result directory: ../../results/GUMI_AE/False_False_False_0_32_4_31_128_128_25_32_0.0001_16384_25_512_0.001_1024/\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = 16 # args.num_workers\n",
    "RESET_DATA = False # args.reset_data\n",
    "\n",
    "USE_UNREAL_IMAGE = False # args.use_unreal_image\n",
    "USE_WORD_IMAGE = False # args.use_word_image\n",
    "USE_UNIQUE_NOUN_BOKE = False # args.use_unique_noun_boke\n",
    "\n",
    "MIN_STAR = 0 # args.min_star\n",
    "MIN_APPER_WORD = 32 # args.min_apper_word\n",
    "MIN_SENTENCE_LENGTH = 4 # args.min_sentence_length\n",
    "MAX_SENTENCE_LENGTH = 31 # args.max_sentence_length\n",
    "\n",
    "RETRAIN_AUTOENCODER = False # args.retrain_autoencoder\n",
    "IMAGE_HEIGHT = 128 # args.image_height\n",
    "IMAGE_WIDTH = 128 # args.image_width\n",
    "AE_EPOCH = 25 # args.ae_epoch\n",
    "AE_BATCH_SIZE = 32 # args.ae_batch_size\n",
    "AE_LEARNING_RATE = 0.0001 # args.ae_learning_rate\n",
    "AE_FEATURE_DIM = 16384 # args.ae_feature_dim\n",
    "\n",
    "EPOCH = 25 # args.epoch\n",
    "BATCH_SIZE = 512 # args.batch_size\n",
    "LEARNING_RATE = 0.001 # args.learning_rate\n",
    "FEATURE_DIM = 1024 # args.feature_dim\n",
    "\n",
    "AE_RESULT_DIR = f\"../../results/Autoencoder/{USE_UNREAL_IMAGE}_{USE_WORD_IMAGE}_{USE_UNIQUE_NOUN_BOKE}_{MIN_STAR}_{MIN_APPER_WORD}_{MIN_SENTENCE_LENGTH}_{MAX_SENTENCE_LENGTH}_{IMAGE_HEIGHT}_{IMAGE_WIDTH}_{AE_EPOCH}_{AE_BATCH_SIZE}_{AE_LEARNING_RATE}_{AE_FEATURE_DIM}/\"\n",
    "\n",
    "if not os.path.exists(\"../../results/Autoencoder/\"):\n",
    "    os.mkdir(\"../../results/Autoencoder/\")\n",
    "if not os.path.exists(AE_RESULT_DIR):\n",
    "    os.mkdir(AE_RESULT_DIR)\n",
    "print(f\"result directory: {AE_RESULT_DIR}\")\n",
    "with open(f\"{AE_RESULT_DIR}config.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"USE_UNREAL_IMAGE\": USE_UNREAL_IMAGE,\n",
    "        \"USE_WORD_IMAGE\": USE_WORD_IMAGE,\n",
    "        \"USE_UNIQUE_NOUN_BOKE\": USE_UNIQUE_NOUN_BOKE,\n",
    "        \"MIN_STAR\": MIN_STAR,\n",
    "        \"MIN_APPER_WORD\": MIN_APPER_WORD,\n",
    "        \"MIN_SENTENCE_LENGTH\": MIN_SENTENCE_LENGTH,\n",
    "        \"MAX_SENTENCE_LENGTH\": MAX_SENTENCE_LENGTH,\n",
    "        \"IMAGE_HEIGHT\": IMAGE_HEIGHT,\n",
    "        \"IMAGE_WIDTH\": IMAGE_WIDTH,\n",
    "        \"EPOCH\": AE_EPOCH,\n",
    "        \"BATCH_SIZE\": AE_BATCH_SIZE,\n",
    "        \"LEARNING_RATE\": AE_LEARNING_RATE,\n",
    "        \"FEATURE_DIM\": AE_FEATURE_DIM,\n",
    "    }, f)\n",
    "\n",
    "RESULT_DIR = f\"../../results/GUMI_AE/{USE_UNREAL_IMAGE}_{USE_WORD_IMAGE}_{USE_UNIQUE_NOUN_BOKE}_{MIN_STAR}_{MIN_APPER_WORD}_{MIN_SENTENCE_LENGTH}_{MAX_SENTENCE_LENGTH}_{IMAGE_HEIGHT}_{IMAGE_WIDTH}_{AE_EPOCH}_{AE_BATCH_SIZE}_{AE_LEARNING_RATE}_{AE_FEATURE_DIM}_{EPOCH}_{BATCH_SIZE}_{LEARNING_RATE}_{FEATURE_DIM}/\"\n",
    "\n",
    "if not os.path.exists(\"../../results/GUMI_AE/\"):\n",
    "    os.mkdir(\"../../results/GUMI_AE/\")\n",
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.mkdir(RESULT_DIR)\n",
    "print(f\"result directory: {RESULT_DIR}\")\n",
    "with open(f\"{RESULT_DIR}config.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"USE_UNREAL_IMAGE\": USE_UNREAL_IMAGE,\n",
    "        \"USE_WORD_IMAGE\": USE_WORD_IMAGE,\n",
    "        \"USE_UNIQUE_NOUN_BOKE\": USE_UNIQUE_NOUN_BOKE,\n",
    "        \"MIN_STAR\": MIN_STAR,\n",
    "        \"MIN_APPER_WORD\": MIN_APPER_WORD,\n",
    "        \"MIN_SENTENCE_LENGTH\": MIN_SENTENCE_LENGTH,\n",
    "        \"MAX_SENTENCE_LENGTH\": MAX_SENTENCE_LENGTH,\n",
    "        \"IMAGE_HEIGHT\": IMAGE_HEIGHT,\n",
    "        \"IMAGE_WIDTH\": IMAGE_WIDTH,\n",
    "        \"EPOCH\": AE_EPOCH,\n",
    "        \"BATCH_SIZE\": AE_BATCH_SIZE,\n",
    "        \"LEARNING_RATE\": AE_LEARNING_RATE,\n",
    "        \"FEATURE_DIM\": AE_FEATURE_DIM,\n",
    "        \"EPOCH\": EPOCH,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE,\n",
    "        \"FEATURE_DIM\": FEATURE_DIM,\n",
    "    }, f)\n",
    "\n",
    "DATA_DIR = \"../../datas/boke_data_assemble/\"\n",
    "IMAGE_DIR = \"../../datas/boke_image/\"\n",
    "\n",
    "IMAGE_FEATURE_DIR = f\"../../datas/encoded/Autoencoder_{USE_UNREAL_IMAGE}_{USE_WORD_IMAGE}_{USE_UNIQUE_NOUN_BOKE}_{MIN_STAR}_{MIN_APPER_WORD}_{MIN_SENTENCE_LENGTH}_{MAX_SENTENCE_LENGTH}_{IMAGE_HEIGHT}_{IMAGE_WIDTH}_{AE_EPOCH}_{AE_BATCH_SIZE}_{AE_LEARNING_RATE}_{AE_FEATURE_DIM}/\"\n",
    "if not os.path.exists(IMAGE_FEATURE_DIR):\n",
    "    os.mkdir(IMAGE_FEATURE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228908, 25435)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(f\"{AE_RESULT_DIR}test_image_paths.json\") or RESET_DATA:\n",
    "    image_paths = list()\n",
    "\n",
    "    for IP in tqdm(os.listdir(IMAGE_DIR)):\n",
    "        \n",
    "        N = int(IP.split(\".\")[0])\n",
    "        if not os.path.exists(f\"{DATA_DIR}{N}.json\"):\n",
    "            continue\n",
    "\n",
    "        with open(f\"{DATA_DIR}{N}.json\", \"r\") as f:\n",
    "            a = json.load(f)\n",
    "        \n",
    "        image_information = a[\"image_information\"]\n",
    "        is_photographic_probability = image_information[\"is_photographic_probability\"]\n",
    "        ocr = image_information[\"ocr\"]\n",
    "\n",
    "        # 現実写真以外を除去\n",
    "        if not USE_UNREAL_IMAGE:\n",
    "            if is_photographic_probability < 0.8: continue\n",
    "            \n",
    "        # 文字のある画像を除去\n",
    "        if not USE_WORD_IMAGE:\n",
    "            if len(ocr) != 0: continue\n",
    "        \n",
    "        image_paths.append(f\"{IMAGE_DIR}{IP}\")\n",
    "\n",
    "    train_image_paths, test_image_paths = train_test_split(image_paths, test_size = 0.1)\n",
    "\n",
    "    with open(f\"{AE_RESULT_DIR}train_image_paths.json\", \"w\") as f:\n",
    "        json.dump(train_image_paths, f)\n",
    "    with open(f\"{AE_RESULT_DIR}test_image_paths.json\", \"w\") as f:\n",
    "        json.dump(test_image_paths, f)\n",
    "    \n",
    "else:\n",
    "    with open(f\"{AE_RESULT_DIR}train_image_paths.json\", \"r\") as f:\n",
    "        train_image_paths = json.load(f)\n",
    "    with open(f\"{AE_RESULT_DIR}test_image_paths.json\", \"r\") as f:\n",
    "        test_image_paths = json.load(f)\n",
    "\n",
    "len(train_image_paths), len(test_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の前処理\n",
    "image_preprocess = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 画像のデータローダを作る関数\n",
    "def make_image_dataloader(image_paths, batch_size, num_workers = 4):\n",
    "\n",
    "    class LoadImageDataset(Dataset):\n",
    "        def __init__(self, image_paths):\n",
    "            \"\"\"\n",
    "                image_paths: 画像のパスからなるリスト\n",
    "            \"\"\"\n",
    "            self.image_paths = image_paths\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.image_paths)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = Image.open(image_paths[idx]).convert(\"RGB\")\n",
    "\n",
    "            return image, self.image_paths[idx]\n",
    "    \n",
    "    def collate_fn_tf(batch):\n",
    "        images = torch.stack([image_preprocess(B[0]) for B in batch])\n",
    "        image_numbers = [B[1] for B in batch]\n",
    "\n",
    "        return images, image_numbers\n",
    "\n",
    "    print(f\"num data: {len(image_paths)}\")\n",
    "\n",
    "    dataset = LoadImageDataset(image_paths)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size = batch_size, \n",
    "        num_workers = num_workers, \n",
    "        collate_fn = collate_fn_tf\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, image_feature_dim):\n",
    "        \"\"\"\n",
    "            image_feature_dim: \n",
    "        \"\"\"\n",
    "        super(ImageEncoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size = 3, stride = 2, padding = 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(16384, 16384)\n",
    "        self.fc2 = nn.Linear(16384, image_feature_dim)\n",
    "    \n",
    "    def forward(self, images):\n",
    "        x = F.leaky_relu( self.conv1(images) )\n",
    "        # 32, 64, 64\n",
    "        x = F.leaky_relu( self.conv2(x) )\n",
    "        # 64, 32, 32\n",
    "        x = F.leaky_relu( self.conv3(x) )\n",
    "        # 128, 16, 16\n",
    "        x = F.leaky_relu( self.conv4(x) )\n",
    "        # 256, 8, 8\n",
    "\n",
    "        x = nn.Flatten()(x)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        return F.leaky_relu(self.fc2(x))\n",
    "\n",
    "class ImageDecoder(nn.Module):\n",
    "    def __init__(self, image_feature_dim):\n",
    "        \"\"\"\n",
    "            image_feature_dim: \n",
    "        \"\"\"\n",
    "        super(ImageDecoder, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(image_feature_dim, 16384)\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(256, 128, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, 32, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
    "        self.deconv4 = nn.ConvTranspose2d(32, 32, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(32, 3, kernel_size = 3, stride = 1, padding = 1)\n",
    "    \n",
    "    def forward(self, image_features):\n",
    "        x = F.leaky_relu(self.fc1(image_features))\n",
    "        x = nn.Unflatten(1, (256, 8, 8))(x)\n",
    "        # 256, 8, 8\n",
    "\n",
    "        x = F.leaky_relu( self.deconv1(x) )\n",
    "        # 128, 16, 16\n",
    "        x = F.leaky_relu( self.deconv2(x) )\n",
    "        # 64, 32, 32\n",
    "        x = F.leaky_relu( self.deconv3(x) )\n",
    "        # 32, 64, 64\n",
    "        x = F.leaky_relu( self.deconv4(x) )\n",
    "        # 32, 128, 128\n",
    "        return nn.Sigmoid()( self.conv1(x) )\n",
    "        # 3, 128, 128\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, image_feature_dim):\n",
    "        \"\"\"\n",
    "            image_feature_dim: \n",
    "        \"\"\"\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = ImageEncoder(image_feature_dim)\n",
    "        self.decoder = ImageDecoder(image_feature_dim)\n",
    "    \n",
    "    def forward(self, images):\n",
    "        return self.decoder( self.encoder(images) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_by_autoencoder(autoeuncoder, image_paths, device = \"cuda\"):\n",
    "    tmp_images = [image_preprocess(Image.open(IP)) for IP in image_paths]\n",
    "    images = torch.stack(tmp_images).to(device)\n",
    "\n",
    "    predict_images = autoencoder(images).permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 5))\n",
    "    for i in range(len(image_paths)):\n",
    "        ax = fig.add_subplot(2, len(image_paths), i + 1)\n",
    "        ax.imshow(tmp_images[i].permute(1, 2, 0))\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(\"input\")\n",
    "\n",
    "        ax = fig.add_subplot(2, len(image_paths), len(image_paths) + i + 1)\n",
    "        ax.imshow(predict_images[i])\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(\"predict\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data: 228908\n"
     ]
    }
   ],
   "source": [
    "train_image_dataloader = make_image_dataloader(train_image_paths, batch_size = AE_BATCH_SIZE, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Is, _ = next(iter(train_image_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i, I in enumerate(Is[:5]):\n",
    "    ax = fig.add_subplot(1, 5, i + 1)\n",
    "    ax.imshow(I.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-73793d91efc4>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  autoencoder.load_state_dict(torch.load(f\"{AE_RESULT_DIR}model_{len(train_loss_history):03}.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data: 228908\n",
      "num data: 25435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25:   0%|          | 0/7154 [00:00<?, ?it/s, train_loss=0.0908]\n",
      "Epoch 2/25:   0%|          | 0/795 [00:00<?, ?it/s, test_loss=0.0841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/25, Train Loss: 0.0000, Test Loss: 0.0001\n",
      "-------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-73793d91efc4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mtest_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{AE_RESULT_DIR}model_{len(train_loss_history):03}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{AE_RESULT_DIR}model_{len(train_loss_history) - 1:03}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{AE_RESULT_DIR}model_{len(train_loss_history) - 1:03}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/.conda/envs/Colab_20241111/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                 \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/.conda/envs/Colab_20241111/lib/python3.10/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not os.path.exists(f\"{AE_RESULT_DIR}history.png\") or RETRAIN_AUTOENCODER:\n",
    "    autoencoder = Autoencoder(image_feature_dim = AE_FEATURE_DIM)\n",
    "\n",
    "    # 学習履歴がある場合，途中から再開する\n",
    "    if os.path.exists(f\"{AE_RESULT_DIR}history.json\"):\n",
    "        with open(f\"{AE_RESULT_DIR}history.json\", \"r\") as f:\n",
    "            a = json.load(f)\n",
    "            train_loss_history = a[\"train_loss\"]\n",
    "            test_loss_history = a[\"test_loss\"]\n",
    "        autoencoder.load_state_dict(torch.load(f\"{AE_RESULT_DIR}model_{len(train_loss_history):03}.pth\"))\n",
    "        START_EPOCH = len(train_loss_history)\n",
    "    else:\n",
    "        train_loss_history = []\n",
    "        test_loss_history = []\n",
    "        START_EPOCH = 0\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    autoencoder.to(device)\n",
    "    optimizer = optim.AdamW(autoencoder.parameters(), lr = AE_LEARNING_RATE)\n",
    "\n",
    "    train_image_dataloader = make_image_dataloader(train_image_paths, batch_size = AE_BATCH_SIZE, num_workers = NUM_WORKERS)\n",
    "    test_image_dataloader = make_image_dataloader(test_image_paths, batch_size = AE_BATCH_SIZE, num_workers = NUM_WORKERS)\n",
    "\n",
    "    # 1イテレーション学習する関数\n",
    "    def train_step_for_autoencoder(autoencoder, optimizer, images):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(images)\n",
    "        loss = nn.MSELoss()(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    # 1イテレーション検証する関数\n",
    "    def test_step_for_autoencoder(model, images):\n",
    "        with torch.no_grad():\n",
    "            outputs = autoencoder(images)\n",
    "            loss = nn.MSELoss()(outputs, images)\n",
    "        return loss.item()\n",
    "\n",
    "    for epoch in range(START_EPOCH, AE_EPOCH):\n",
    "\n",
    "        # train\n",
    "        train_loss_obj = 0.0\n",
    "        autoencoder.train()\n",
    "        pb = tqdm(train_image_dataloader, desc = f\"Epoch {epoch+1}/{AE_EPOCH}\")\n",
    "        \n",
    "        for images, _ in pb:\n",
    "            images = images.float().to(\"cuda\")\n",
    "\n",
    "            loss = train_step_for_autoencoder(autoencoder, optimizer, images)\n",
    "            train_loss_obj += loss\n",
    "            pb.set_postfix({\"train_loss\": train_loss_obj / (pb.n + 1),})\n",
    "            break\n",
    "        train_loss = train_loss_obj / len(train_image_dataloader)\n",
    "\n",
    "        # test\n",
    "        test_loss_obj = 0.0\n",
    "        autoencoder.eval()\n",
    "        pb = tqdm(test_image_dataloader, desc = f\"Epoch {epoch+1}/{AE_EPOCH}\")\n",
    "        \n",
    "        for images, _ in pb:\n",
    "            images = images.to(device)\n",
    "\n",
    "            loss = test_step_for_autoencoder(autoencoder, images)\n",
    "            test_loss_obj += loss\n",
    "            pb.set_postfix({\"test_loss\": test_loss_obj / (pb.n + 1),})\n",
    "            break\n",
    "        test_loss = test_loss_obj / len(test_image_dataloader)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{AE_EPOCH}, \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "        print(\"-\" * 25)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        test_loss_history.append(test_loss)\n",
    "\n",
    "        torch.save(autoencoder.state_dict(), f\"{AE_RESULT_DIR}model_{len(train_loss_history):03}.pth\")\n",
    "        if os.path.exists(f\"{AE_RESULT_DIR}model_{len(train_loss_history) - 1:03}.pth\"):\n",
    "            os.remove(f\"{AE_RESULT_DIR}model_{len(train_loss_history) - 1:03}.pth\")\n",
    "\n",
    "        # 検証誤差を更新した場合、重みを保存\n",
    "        if min(test_loss_history) == test_loss:\n",
    "            torch.save(autoencoder.state_dict(), f\"{AE_RESULT_DIR}best_model.pth\")\n",
    "\n",
    "        # 学習結果を保存\n",
    "        with open(f\"{AE_RESULT_DIR}history.json\", \"w\") as f:\n",
    "            json.dump({\n",
    "                \"train_loss\": train_loss_history,\n",
    "                \"test_loss\": test_loss_history,\n",
    "            }, f)\n",
    "\n",
    "        predict_by_autoencoder(autoencoder, test_image_paths[:5])\n",
    "\n",
    "    # 学習結果を描画\n",
    "    fig = plt.figure(figsize = (5, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(train_loss_history, label = \"train\")\n",
    "    ax.plot(test_loss_history, label = \"test\")\n",
    "    ax.set_xlabel(\"epoch\")\n",
    "    ax.set_ylabel(\"loss\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "\n",
    "    fig.savefig(f\"{AE_RESULT_DIR}history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習に用いる大喜利の数: 2030920\n",
      " 検証に用いる大喜利の数: 20515\n",
      " 使用する画像の数: 244286\n",
      " 単語の種類: 16705\n"
     ]
    }
   ],
   "source": [
    "# データセットの作成\n",
    "if not os.path.exists(f\"{RESULT_DIR}index_to_word.json\") or RESET_DATA:\n",
    "    # tokenizer\n",
    "    with open('Japanese_BPEEncoder_V2/ja-swe32kfix.txt') as f:\n",
    "        bpe = f.read().split('\\n')\n",
    "\n",
    "    with open('Japanese_BPEEncoder_V2/emoji.json') as f:\n",
    "        emoji = json.loads(f.read())\n",
    "\n",
    "    tokenizer = SWEEncoder_ja(bpe, emoji)\n",
    "\n",
    "    tmp = list()\n",
    "    word_count_dict = dict()\n",
    "\n",
    "    for JP in tqdm(os.listdir(DATA_DIR)):\n",
    "        \n",
    "        N = int(JP.split(\".\")[0])\n",
    "\n",
    "        with open(f\"{DATA_DIR}{JP}\", \"r\") as f:\n",
    "            a = json.load(f)\n",
    "        \n",
    "        image_information = a[\"image_information\"]\n",
    "        is_photographic_probability = image_information[\"is_photographic_probability\"]\n",
    "        ocr = image_information[\"ocr\"]\n",
    "\n",
    "        # 現実写真以外を除去\n",
    "        if not USE_UNREAL_IMAGE:\n",
    "            if is_photographic_probability < 0.8: continue\n",
    "            \n",
    "        # 文字のある画像を除去\n",
    "        if not USE_WORD_IMAGE:\n",
    "            if len(ocr) != 0: continue\n",
    "        \n",
    "        bokes = a[\"bokes\"]\n",
    "\n",
    "        for B in bokes:\n",
    "            # 星が既定の数以下の大喜利を除去\n",
    "            if B[\"star\"] < MIN_STAR:\n",
    "                continue\n",
    "\n",
    "            # 固有名詞を含む大喜利を除去\n",
    "            if not USE_UNIQUE_NOUN_BOKE:\n",
    "                if len(B[\"unique_nouns\"]) != 0: continue\n",
    "\n",
    "            tokenized_boke = tokenizer.encode(B[\"boke\"])\n",
    "            # 単語数が既定の数でない大喜利を除去\n",
    "            if not MIN_SENTENCE_LENGTH <= len(tokenized_boke) < MAX_SENTENCE_LENGTH:\n",
    "                continue\n",
    "\n",
    "            for W in tokenized_boke:\n",
    "                try:\n",
    "                    word_count_dict[W] += 1\n",
    "                except:\n",
    "                    word_count_dict[W] = 1\n",
    "            \n",
    "            tmp.append({\n",
    "                \"image_number\": N,\n",
    "                \"tokenized_boke\": tokenized_boke\n",
    "            })\n",
    "\n",
    "    # 単語の最小出現回数を満たさない大喜利を除去\n",
    "    boke_datas = list()\n",
    "    words = list()\n",
    "\n",
    "    for D in tqdm(tmp):\n",
    "        flag = False\n",
    "        for W in D[\"tokenized_boke\"]:\n",
    "            if word_count_dict[W] < MIN_APPER_WORD:\n",
    "                flag = True\n",
    "                break\n",
    "        if flag: \n",
    "            continue\n",
    "        \n",
    "        boke_datas.append({\n",
    "            \"image_number\": D[\"image_number\"],\n",
    "            \"tokenized_boke\": D[\"tokenized_boke\"]\n",
    "        })\n",
    "        words += D[\"tokenized_boke\"]\n",
    "    words = set(words)\n",
    "    image_numbers = list(set([D[\"image_number\"] for D in boke_datas]))\n",
    "    del tmp\n",
    "\n",
    "    # tokenize\n",
    "    index_to_index = dict()\n",
    "\n",
    "    c = 3\n",
    "    for D in tqdm(boke_datas):\n",
    "        tmp = list()\n",
    "        for W in D[\"tokenized_boke\"]:\n",
    "            try:\n",
    "                index_to_index[W]\n",
    "            except:\n",
    "                index_to_index[W] = c\n",
    "                c += 1\n",
    "            tmp.append(index_to_index[W])\n",
    "        D[\"tokenized_boke\"] = [1] + tmp + [2]\n",
    "\n",
    "    index_to_word = {\n",
    "        V: tokenizer.decode([K]) for K, V in index_to_index.items()\n",
    "    }\n",
    "    index_to_word[0] = \"<PAD>\"\n",
    "    index_to_word[1] = \"<START>\"\n",
    "    index_to_word[2] = \"<END>\"\n",
    "\n",
    "    #\n",
    "    train_boke_datas, test_boke_datas = train_test_split(boke_datas, test_size = 0.01)\n",
    "\n",
    "    with open(f\"{RESULT_DIR}train_boke_datas.json\", \"w\") as f:\n",
    "        json.dump(train_boke_datas, f)\n",
    "    with open(f\"{RESULT_DIR}test_boke_datas.json\", \"w\") as f:\n",
    "        json.dump(test_boke_datas, f)\n",
    "    with open(f\"{RESULT_DIR}index_to_word.json\", \"w\") as f:\n",
    "        json.dump(index_to_word, f)\n",
    "\n",
    "else:\n",
    "    with open(f\"{RESULT_DIR}train_boke_datas.json\", \"r\") as f:\n",
    "        train_boke_datas = json.load(f)\n",
    "    with open(f\"{RESULT_DIR}test_boke_datas.json\", \"r\") as f:\n",
    "        test_boke_datas = json.load(f)\n",
    "    with open(f\"{RESULT_DIR}index_to_word.json\", \"r\") as f:\n",
    "        index_to_word = json.load(f)\n",
    "\n",
    "    image_numbers = [D[\"image_number\"] for D in train_boke_datas] + [D[\"image_number\"] for D in test_boke_datas]\n",
    "    image_numbers = list(set(image_numbers))\n",
    "\n",
    "print(f\"学習に用いる大喜利の数: {len(train_boke_datas)}\\n\", \n",
    "      f\"検証に用いる大喜利の数: {len(test_boke_datas)}\\n\",\n",
    "      f\"使用する画像の数: {len(image_numbers)}\\n\",\n",
    "      f\"単語の種類: {len(index_to_word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を特徴量に変換する\n",
    "if RETRAIN_AUTOENCODER:\n",
    "    shutil.rmtree(IMAGE_FEATURE_DIR) \n",
    "    os.mkdir(IMAGE_FEATURE_DIR)\n",
    "\n",
    "tmp = list()\n",
    "for IN in tqdm(image_numbers):\n",
    "    if os.path.exists(f\"{IMAGE_FEATURE_DIR}{IN}.npy\"):\n",
    "        continue\n",
    "    tmp.append(f\"{IMAGE_DIR}{IN}.jpg\")\n",
    "\n",
    "if len(tmp) != 0:\n",
    "    image_dataloader = make_image_dataloader(tmp, batch_size = 128, num_workers = NUM_WORKERS)\n",
    "\n",
    "    # encoder of Autoencoder\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    autoencoder = Autoencoder(image_feature_dim = AE_FEATURE_DIM)\n",
    "    autoencoder.load_state_dict(torch.load(f\"{AE_RESULT_DIR}best_model.pth\"))\n",
    "    model = autoencoder.encoder\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for Is, IPs in tqdm(image_dataloader):\n",
    "        Is = Is.to(device)\n",
    "        features = model(Is).detach().cpu().numpy()\n",
    "\n",
    "        for f, IP in zip(features, IPs):\n",
    "            N = IP.split(\"/\")[-1].split(\".\")[0]\n",
    "            np.save(f\"{IMAGE_FEATURE_DIR}{N}\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大喜利生成AIの学習用データローダを作る関数\n",
    "def make_dataloader(boke_datas, max_sentence_length, num_workers = 4):\n",
    "    \"\"\"\n",
    "        boke_datas: {\"image_number\":画像のお題番号 ,\"tokenized_boke\":トークナイズされた大喜利}からなるリスト\n",
    "        max_sentence_length: 学習データの最大単語数(<START>, <END>トークンを含まない)\n",
    "        num_workers: データローダが使用するCPUのスレッド数\n",
    "    \"\"\"\n",
    "    class SentenceGeneratorDataset(Dataset):\n",
    "        def __init__(self, image_file_numbers, sentences, teacher_signals):\n",
    "            \"\"\"\n",
    "                image_file_numbers: 画像の番号からなるリスト\n",
    "                sentences: 入力文章からなるリスト\n",
    "                teacher_signals: 教師信号からなるリスト\n",
    "            \"\"\"\n",
    "            if len(image_file_numbers) != len(sentences) and len(teacher_signals) != len(sentences):\n",
    "                raise ValueError(\"データリストの長さが一致しません\")\n",
    "\n",
    "            self.image_file_numbers = image_file_numbers\n",
    "            self.sentences = sentences\n",
    "            self.teacher_signals = teacher_signals\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.teacher_signals)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image_feature = np.load(f\"{IMAGE_FEATURE_DIR}{self.image_file_numbers[idx]}.npy\")\n",
    "            sentence = self.sentences[idx]\n",
    "            teacher_signal = self.teacher_signals[idx]\n",
    "\n",
    "            return image_feature, sentence, teacher_signal\n",
    "\n",
    "    def collate_fn_tf(batch):\n",
    "        image_features = torch.tensor(np.array([B[0] for B in batch]))\n",
    "        sentences = torch.tensor(np.array([B[1] for B in batch]))\n",
    "        teacher_signals = torch.tensor(np.array([B[2] for B in batch]))\n",
    "\n",
    "        return image_features, sentences, teacher_signals\n",
    "\n",
    "    image_file_numbers = list()\n",
    "    sentences = list()\n",
    "    teacher_signals = list()\n",
    "\n",
    "    for D in tqdm(boke_datas):\n",
    "        image_file_numbers.append(D[\"image_number\"])\n",
    "        tmp = D[\"tokenized_boke\"] + [0] * (2 + max_sentence_length - len(D[\"tokenized_boke\"]))\n",
    "        sentences.append(tmp[:-1])\n",
    "        teacher_signals.append(tmp[1:])\n",
    "\n",
    "    dataset = SentenceGeneratorDataset(image_file_numbers, sentences, teacher_signals)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size = BATCH_SIZE, \n",
    "        num_workers = num_workers, \n",
    "        collate_fn = collate_fn_tf\n",
    "    )\n",
    "\n",
    "    print(f\"num data: {len(teacher_signals)}\")\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大喜利生成モデルのクラス\n",
    "class BokeGeneratorModel(nn.Module):\n",
    "    def __init__(self, num_word, image_feature_dim, sentence_length, feature_dim = 1024):\n",
    "        \"\"\"\n",
    "            num_word: 学習に用いる単語の総数\n",
    "            image_feature_dim: 画像の特徴量の次元数\n",
    "            sentence_length: 入力する文章の単語数\n",
    "            feature_dim: 特徴量次元数\n",
    "        \"\"\"\n",
    "        super(BokeGeneratorModel, self).__init__()\n",
    "        self.num_word = num_word\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "        self.sentence_length = sentence_length\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(image_feature_dim, feature_dim)\n",
    "        self.embedding = nn.Embedding(num_word, feature_dim, padding_idx = 0)\n",
    "        self.lstm = nn.LSTM(input_size = feature_dim, hidden_size = feature_dim, \n",
    "                            batch_first = True)\n",
    "        self.fc2 = nn.Linear(feature_dim + feature_dim, 2 * feature_dim)\n",
    "        self.fc3 = nn.Linear(2 * feature_dim, 2 * feature_dim)\n",
    "        self.fc4 = nn.Linear(2 * feature_dim, num_word)\n",
    "    \n",
    "    # LSTMの初期値は0で，画像の特徴量と文章の特徴量を全結合層の前で結合する\n",
    "    def forward(self, image_features, sentences):\n",
    "        \"\"\"\n",
    "            image_features: 画像の特徴量\n",
    "            sentences: 入力する文章\n",
    "        \"\"\"\n",
    "        x1 = F.leaky_relu(self.fc1(image_features))\n",
    "        x1 = x1.unsqueeze(1).repeat(1, self.sentence_length, 1)\n",
    "\n",
    "        x2 = self.embedding(sentences)\n",
    "        x2, _ = self.lstm(x2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim = -1)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章生成の精度を計算する関数\n",
    "def calculate_accuracy(teacher_signals, outputs):\n",
    "    \"\"\"\n",
    "        teacher_signals: 教師信号\n",
    "        outputs: モデルの出力\n",
    "    \"\"\"\n",
    "    _, predicted_words = outputs.max(dim = -1)\n",
    "    # パディングに対して精度を計算しない\n",
    "    mask = (teacher_signals != 0)\n",
    "    correct = ((predicted_words == teacher_signals) & mask).sum().item()\n",
    "    total = mask.sum().item()\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return accuracy\n",
    "\n",
    "# 1イテレーション学習する関数\n",
    "def train_step(model, optimizer, batch_data, batch_labels):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(*batch_data)\n",
    "    # パディングに対して損失を計算しない\n",
    "    loss = F.cross_entropy(outputs.view(-1, outputs.size(-1)), batch_labels.view(-1),\n",
    "                           ignore_index = 0)\n",
    "    accuracy = calculate_accuracy(batch_labels, F.softmax(outputs, dim = -1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), accuracy\n",
    "\n",
    "# 1イテレーション検証する関数\n",
    "def evaluate(model, batch_data, batch_labels):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(*batch_data)\n",
    "        loss = F.cross_entropy(outputs.view(-1, outputs.size(-1)), batch_labels.view(-1),\n",
    "                               ignore_index = 0)\n",
    "        accuracy = calculate_accuracy(batch_labels, F.softmax(outputs, dim = -1))\n",
    "    return loss.item(), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2030920/2030920 [00:05<00:00, 376869.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data: 2030920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = make_dataloader(train_boke_datas, max_sentence_length = MAX_SENTENCE_LENGTH, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IF, S, T = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1265e+00,  5.4682e-01, -2.6377e-03,  ...,  1.2396e+00,\n",
       "          7.9547e-01,  8.7314e-01],\n",
       "        [ 2.0829e+00,  2.1133e+00, -4.2770e-03,  ..., -7.7618e-03,\n",
       "         -2.4371e-03,  1.7146e+00],\n",
       "        [ 1.0221e+00, -2.7735e-03,  3.3475e-01,  ...,  1.1960e+00,\n",
       "         -1.9723e-02,  1.2980e+00],\n",
       "        ...,\n",
       "        [ 3.0247e+00,  5.6076e-01,  4.3437e+00,  ..., -1.5713e-02,\n",
       "         -1.9582e-02, -3.1424e-03],\n",
       "        [ 9.3699e-01,  6.0997e-01,  1.5403e+00,  ...,  2.6746e+00,\n",
       "         -1.0381e-02,  7.8680e-01],\n",
       "        [ 2.4179e+00,  1.4890e+00, -9.4017e-03,  ..., -1.0710e-02,\n",
       "         -5.7778e-02, -3.8969e-03]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = make_dataloader(train_boke_datas, max_sentence_length = MAX_SENTENCE_LENGTH, num_workers = NUM_WORKERS)\n",
    "test_dataloader = make_dataloader(test_boke_datas, max_sentence_length = MAX_SENTENCE_LENGTH, num_workers = NUM_WORKERS)\n",
    "\n",
    "model = BokeGeneratorModel(num_word = len(index_to_word), \n",
    "                           image_feature_dim = AE_FEATURE_DIM, \n",
    "                           sentence_length = MAX_SENTENCE_LENGTH + 1, \n",
    "                           feature_dim = FEATURE_DIM)\n",
    "\n",
    "# 学習履歴がある場合，途中から再開する\n",
    "if os.path.exists(f\"{RESULT_DIR}history.json\"):\n",
    "    with open(f\"{RESULT_DIR}history.json\", \"r\") as f:\n",
    "        a = json.load(f)\n",
    "        train_loss_history = a[\"train_loss\"]\n",
    "        train_accuracy_history = a[\"train_accuracy\"]\n",
    "        test_loss_history = a[\"test_loss\"]\n",
    "        test_accuracy_history = a[\"test_accuracy\"]\n",
    "    model.load_state_dict(torch.load(f\"{RESULT_DIR}model_{len(train_loss_history):03}.pth\"))\n",
    "    SATRT_EPOCH = len(train_loss_history)\n",
    "else:\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    SATRT_EPOCH = 0\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(SATRT_EPOCH, EPOCH):\n",
    "\n",
    "    # train\n",
    "    train_loss_obj = 0.0\n",
    "    train_accuracy_obj = 0.0\n",
    "    model.train()\n",
    "    pb = tqdm(train_dataloader, desc = f\"Epoch {epoch+1}/{EPOCH}\")\n",
    "    \n",
    "    for image_features, sentences, teacher_signals in pb:\n",
    "        image_features = image_features.to(device)\n",
    "        sentences = sentences.to(device)\n",
    "        teacher_signals = teacher_signals.to(device)\n",
    "        \n",
    "        loss, accuracy = train_step(model, optimizer, (image_features, sentences), teacher_signals)\n",
    "        train_loss_obj += loss\n",
    "        train_accuracy_obj += accuracy\n",
    "        pb.set_postfix({\"train_loss\": train_loss_obj / (pb.n + 1), \"train_accuracy\": train_accuracy_obj / (pb.n + 1)})\n",
    "        break\n",
    "    train_loss = train_loss_obj / len(train_dataloader)\n",
    "    train_accuracy = train_accuracy_obj / len(train_dataloader)\n",
    "\n",
    "    # test\n",
    "    test_loss_obj = 0.0\n",
    "    test_accuracy_obj = 0.0\n",
    "    model.eval()\n",
    "    pb = tqdm(test_dataloader, desc = \"Evaluating\")\n",
    "\n",
    "    for image_features, sentences, teacher_signals in pb:\n",
    "        image_features = image_features.to(device)\n",
    "        sentences = sentences.to(device)\n",
    "        teacher_signals = teacher_signals.to(device)\n",
    "\n",
    "        loss, accuracy = evaluate(model, (image_features, sentences), teacher_signals)\n",
    "        test_loss_obj += loss\n",
    "        test_accuracy_obj += accuracy\n",
    "        pb.set_postfix({\"test_loss\": test_loss_obj / (pb.n + 1), \"test_accuracy\": test_accuracy_obj / (pb.n + 1)})\n",
    "        break\n",
    "    test_loss = test_loss_obj / len(test_dataloader)\n",
    "    test_accuracy = test_accuracy_obj / len(test_dataloader)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{EPOCH}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_accuracy_history.append(test_accuracy)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{RESULT_DIR}model_{len(train_loss_history):03}.pth\")\n",
    "    if os.path.exists(f\"{RESULT_DIR}model_{len(train_loss_history) - 1:03}.pth\"):\n",
    "        os.remove(f\"{RESULT_DIR}model_{len(train_loss_history) - 1:03}.pth\")\n",
    "\n",
    "    # 学習精度を更新した場合、重みを保存\n",
    "    if max(train_accuracy_history) == train_accuracy:\n",
    "        torch.save(model.state_dict(), f\"{RESULT_DIR}best_model.pth\")\n",
    "    \n",
    "    # 学習結果を保存\n",
    "    with open(f\"{RESULT_DIR}history.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"train_loss\": train_loss_history,\n",
    "            \"train_accuracy\": train_accuracy_history,\n",
    "            \"test_loss\": test_loss_history,\n",
    "            \"test_accuracy\": test_accuracy_history\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果を描画\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(train_loss_history, label = \"train\")\n",
    "ax.plot(test_loss_history, label = \"test\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(train_accuracy_history, label = \"train\")\n",
    "ax.plot(test_accuracy_history, label = \"test\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "fig.savefig(f\"{RESULT_DIR}history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大喜利生成AI\n",
    "class NeuralJokingMachine:\n",
    "    def __init__(self, weight_path, ae_weight_path, index_to_word, sentence_length, feature_dim = 1024, ae_feature_dim = 16384):\n",
    "        \"\"\"\n",
    "            weight_path: 大喜利適合判定モデルの学習済みの重みのパス\n",
    "            ae_weight_path: \n",
    "            index_to_word: 単語のID: 単語の辞書(0:<PAD>, 1:<START>, 2:<END>)\n",
    "            sentence_length: 入力する文章の単語数\n",
    "            feature_dim: 特徴量次元数\n",
    "            ae_feature_dim: \n",
    "        \"\"\"\n",
    "        self.index_to_word = index_to_word\n",
    "        self.sentence_length = sentence_length\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.boke_generate_model = BokeGeneratorModel(\n",
    "                                        num_word = len(index_to_word), \n",
    "                                        image_feature_dim = ae_feature_dim, \n",
    "                                        sentence_length = sentence_length, \n",
    "                                        feature_dim = feature_dim)\n",
    "        self.boke_generate_model.load_state_dict(torch.load(weight_path))\n",
    "        self.boke_generate_model.to(self.device)\n",
    "        self.boke_generate_model.eval()\n",
    "\n",
    "        self.autoencoder = Autoencoder(image_feature_dim = ae_feature_dim)\n",
    "        self.autoencoder.load_state_dict(torch.load(ae_weight_path))\n",
    "        self.encoder = self.autoencoder.encoder\n",
    "        self.encoder = self.encoder.to(self.device)\n",
    "        self.encoder.eval()\n",
    "\n",
    "        # 画像の前処理\n",
    "        self.image_preprocesser = transforms.Compose([\n",
    "            transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, image_path, argmax = False, top_k = 5):\n",
    "        \"\"\"\n",
    "            image_path: 大喜利を生成したい画像のパス\n",
    "            argmax: Trueなら最大確率の単語を選ぶ, FalseならTop-Kサンプリングを行う\n",
    "            top_k: Top-Kサンプリング時に考慮する単語の数\n",
    "        \"\"\"\n",
    "        image = Image.open(image_path)\n",
    "        preprocessed_image = self.image_preprocesser(image).to(self.device)\n",
    "        image_feature = self.encoder( preprocessed_image.unsqueeze(0) ) # (1, 2048)\n",
    "        \n",
    "        generated_text = [1] # <START>トークン\n",
    "        for i in range(1, self.sentence_length):\n",
    "            tmp = generated_text + [0] * (self.sentence_length - i) # Padding\n",
    "            tmp = torch.Tensor(np.array(tmp)).unsqueeze(0).to(self.device).to(dtype=torch.int32) # (1, sentence_length)\n",
    "            pred = self.boke_generate_model(image_feature, tmp) # (1, sentence_length, num_word)\n",
    "            target_pred = pred[0][i - 1]\n",
    "\n",
    "            if argmax:\n",
    "                # 最大確率の単語を選ぶ\n",
    "                chosen_id = torch.argmax(target_pred).item()\n",
    "            else:\n",
    "                # Top-Kサンプリング\n",
    "                top_k_probs, top_k_indices = torch.topk(target_pred, top_k)\n",
    "                top_k_probs = torch.nn.functional.softmax(top_k_probs, dim = -1)\n",
    "                chosen_id = np.random.choice(top_k_indices.detach().cpu().numpy(), \n",
    "                                             p = top_k_probs.detach().cpu().numpy())\n",
    "            \n",
    "            generated_text.append(chosen_id)\n",
    "            if chosen_id == 2:\n",
    "                break\n",
    "        \n",
    "        generated_sentence = \"\"\n",
    "        for I in generated_text[1:-1]:\n",
    "            generated_sentence += self.index_to_word[I]\n",
    "        return generated_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-e5c4766616ca>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.boke_generate_model.load_state_dict(torch.load(weight_path))\n",
      "<ipython-input-23-e5c4766616ca>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.autoencoder.load_state_dict(torch.load(ae_weight_path))\n"
     ]
    }
   ],
   "source": [
    "model = NeuralJokingMachine(weight_path = f\"{RESULT_DIR}best_model.pth\",\n",
    "                    ae_weight_path = f\"{AE_RESULT_DIR}best_model.pth\",\n",
    "                    index_to_word = {\n",
    "                        int(K): V for K, V in index_to_word.items()\n",
    "                    },\n",
    "                    sentence_length = 32, \n",
    "                    feature_dim = 1024, \n",
    "                    ae_feature_dim = 16384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../results/Autoencoder/False_False_False_0_32_4_31_128_128_25_32_0.0001_16384/best_model.pth'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{AE_RESULT_DIR}best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../results/GUMI_AE/False_False_False_0_32_4_31_128_128_25_32_0.0001_16384_25_512_0.001_1024/best_model.pth'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{RESULT_DIR}best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'この中に間違った文字を発見しました！'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\"../Line_Bot/tmp.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Colab_20241111",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
