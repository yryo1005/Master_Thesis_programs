{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import subprocess\n",
    "if not os.path.exists(\"Japanese_BPEEncoder_V2\"):\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/tanreinama/Japanese-BPEEncoder_V2.git\", \"Japanese_BPEEncoder_V2\"])\n",
    "from Japanese_BPEEncoder_V2.encode_swe import SWEEncoder_ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # コマンドライン引数の処理\n",
    "# parser = argparse.ArgumentParser(description=\"設定用プログラム\")\n",
    "\n",
    "# parser.add_argument(\"--num_workers\", type = int, default = 16, help = \"データローダが使用するCPUのスレッド数(GPUの総スレッド数の8割が推奨)\")\n",
    "# parser.add_argument(\"--reset_data\", action = \"store_true\", help = \"データセットを再作成するか\")\n",
    "# parser.add_argument(\"--use_unreal_image\", action = \"store_true\", help = \"現実写真以外を使用する\")\n",
    "# parser.add_argument(\"--use_word_image\", action = \"store_true\", help = \"文字を含む画像を使用する\")\n",
    "# parser.add_argument(\"--use_unique_noun_boke\", action = \"store_true\", help = \"固有名詞を含む大喜利を使用する\")\n",
    "# parser.add_argument(\"--min_star\", type = int, default = 0, help = \"大喜利の最小の星の数\")\n",
    "# parser.add_argument(\"--min_apper_word\", type = int, default = 32, help = \"単語の最小出現回数\")\n",
    "# parser.add_argument(\"--min_sentence_length\", type = int, default = 4, help = \"大喜利の最小単語数\")\n",
    "# parser.add_argument(\"--max_sentence_length\", type = int, default = 31, help = \"大喜利の最大単語数\")\n",
    "# parser.add_argument(\"--epoch\", type = int, default = 25, help = \"学習反復回数\")\n",
    "# parser.add_argument(\"--batch_size\", type = int, default = 512, help = \"バッチサイズ\")\n",
    "# parser.add_argument(\"--learning_rate\", type = float, default = 0.001, help = \"学習率\")\n",
    "# parser.add_argument(\"--feature_dim\", type = int, default = 1024, help = \"モデルの特徴量次元数\")\n",
    "\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result directory: ../../results/Neural_Joking_Machine/False_False_False_0_32_4_31_25_512_0.001_1024/\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = 16 # args.num_workers\n",
    "RESET_DATA = False # args.reset_data\n",
    "\n",
    "USE_UNREAL_IMAGE = False # args.use_unreal_image\n",
    "USE_WORD_IMAGE = False # args.use_word_image\n",
    "USE_UNIQUE_NOUN_BOKE = False # args.use_unique_noun_boke\n",
    "\n",
    "MIN_STAR = 0 # args.min_star\n",
    "MIN_APPER_WORD = 32 # args.min_apper_word\n",
    "MIN_SENTENCE_LENGTH = 4 # args.min_sentence_length\n",
    "MAX_SENTENCE_LENGTH = 31 # args.max_sentence_length\n",
    "\n",
    "EPOCH = 25 # args.epoch\n",
    "BATCH_SIZE = 512 # args.batch_size\n",
    "LEARNING_RATE = 0.001 # args.learning_rate\n",
    "FEATURE_DIM = 1024 # args.feature_dim\n",
    "\n",
    "RESULT_DIR = f\"../../results/Neural_Joking_Machine/{USE_UNREAL_IMAGE}_{USE_WORD_IMAGE}_{USE_UNIQUE_NOUN_BOKE}_{MIN_STAR}_{MIN_APPER_WORD}_{MIN_SENTENCE_LENGTH}_{MAX_SENTENCE_LENGTH}_{EPOCH}_{BATCH_SIZE}_{LEARNING_RATE}_{FEATURE_DIM}/\"\n",
    "\n",
    "if not os.path.exists(\"../../results/Neural_Joking_Machine/\"):\n",
    "    os.mkdir(\"../../results/Neural_Joking_Machine/\")\n",
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.mkdir(RESULT_DIR)\n",
    "print(f\"result directory: {RESULT_DIR}\")\n",
    "with open(f\"{RESULT_DIR}config.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"USE_UNREAL_IMAGE\": USE_UNREAL_IMAGE,\n",
    "        \"USE_WORD_IMAGE\": USE_WORD_IMAGE,\n",
    "        \"USE_UNIQUE_NOUN_BOKE\": USE_UNIQUE_NOUN_BOKE,\n",
    "        \"MIN_STAR\": MIN_STAR,\n",
    "        \"MIN_APPER_WORD\": MIN_APPER_WORD,\n",
    "        \"MIN_SENTENCE_LENGTH\": MIN_SENTENCE_LENGTH,\n",
    "        \"MAX_SENTENCE_LENGTH\": MAX_SENTENCE_LENGTH,\n",
    "        \"EPOCH\": EPOCH,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE,\n",
    "        \"FEATURE_DIM\": FEATURE_DIM\n",
    "    }, f)\n",
    "\n",
    "DATA_DIR = \"../../datas/boke_data_assemble/\"\n",
    "IMAGE_DIR = \"../../datas/boke_image/\"\n",
    "\n",
    "IMAGE_FEATURE_DIR = \"../../datas/encoded/resnet152_image_feature/\"\n",
    "if not os.path.exists(IMAGE_FEATURE_DIR):\n",
    "    os.mkdir(IMAGE_FEATURE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 668970/668970 [05:24<00:00, 2062.01it/s]\n",
      "100%|██████████| 2135982/2135982 [00:03<00:00, 561619.87it/s]\n",
      "100%|██████████| 2051435/2051435 [00:02<00:00, 779384.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習に用いる大喜利の数: 2030920\n",
      " 検証に用いる大喜利の数: 20515\n",
      " 使用する画像の数: 244286\n",
      " 単語の種類: 16705\n"
     ]
    }
   ],
   "source": [
    "# データセットの作成\n",
    "if not os.path.exists(f\"{RESULT_DIR}index_to_word.json\") or RESET_DATA:\n",
    "    # tokenizer\n",
    "    with open('Japanese_BPEEncoder_V2/ja-swe32kfix.txt') as f:\n",
    "        bpe = f.read().split('\\n')\n",
    "\n",
    "    with open('Japanese_BPEEncoder_V2/emoji.json') as f:\n",
    "        emoji = json.loads(f.read())\n",
    "\n",
    "    tokenizer = SWEEncoder_ja(bpe, emoji)\n",
    "\n",
    "    tmp = list()\n",
    "    word_count_dict = dict()\n",
    "\n",
    "    for JP in tqdm(os.listdir(DATA_DIR)):\n",
    "        \n",
    "        N = int(JP.split(\".\")[0])\n",
    "\n",
    "        with open(f\"{DATA_DIR}{JP}\", \"r\") as f:\n",
    "            a = json.load(f)\n",
    "        \n",
    "        image_information = a[\"image_information\"]\n",
    "        is_photographic_probability = image_information[\"is_photographic_probability\"]\n",
    "        ocr = image_information[\"ocr\"]\n",
    "\n",
    "        # 現実写真以外を除去\n",
    "        if not USE_UNREAL_IMAGE:\n",
    "            if is_photographic_probability < 0.8: continue\n",
    "            \n",
    "        # 文字のある画像を除去\n",
    "        if not USE_WORD_IMAGE:\n",
    "            if len(ocr) != 0: continue\n",
    "        \n",
    "        bokes = a[\"bokes\"]\n",
    "\n",
    "        for B in bokes:\n",
    "            # 星が既定の数以下の大喜利を除去\n",
    "            if B[\"star\"] < MIN_STAR:\n",
    "                continue\n",
    "\n",
    "            # 固有名詞を含む大喜利を除去\n",
    "            if not USE_UNIQUE_NOUN_BOKE:\n",
    "                if len(B[\"unique_nouns\"]) != 0: continue\n",
    "\n",
    "            tokenized_boke = tokenizer.encode(B[\"boke\"])\n",
    "            # 単語数が既定の数でない大喜利を除去\n",
    "            if not MIN_SENTENCE_LENGTH <= len(tokenized_boke) < MAX_SENTENCE_LENGTH:\n",
    "                continue\n",
    "\n",
    "            for W in tokenized_boke:\n",
    "                try:\n",
    "                    word_count_dict[W] += 1\n",
    "                except:\n",
    "                    word_count_dict[W] = 1\n",
    "            \n",
    "            tmp.append({\n",
    "                \"image_number\": N,\n",
    "                \"tokenized_boke\": tokenized_boke\n",
    "            })\n",
    "\n",
    "    # 単語の最小出現回数を満たさない大喜利を除去\n",
    "    boke_datas = list()\n",
    "    words = list()\n",
    "\n",
    "    for D in tqdm(tmp):\n",
    "        flag = False\n",
    "        for W in D[\"tokenized_boke\"]:\n",
    "            if word_count_dict[W] < MIN_APPER_WORD:\n",
    "                flag = True\n",
    "                break\n",
    "        if flag: \n",
    "            continue\n",
    "        \n",
    "        boke_datas.append({\n",
    "            \"image_number\": D[\"image_number\"],\n",
    "            \"tokenized_boke\": D[\"tokenized_boke\"]\n",
    "        })\n",
    "        words += D[\"tokenized_boke\"]\n",
    "    words = set(words)\n",
    "    image_numbers = list(set([D[\"image_number\"] for D in boke_datas]))\n",
    "    del tmp\n",
    "\n",
    "    # tokenize\n",
    "    index_to_index = dict()\n",
    "\n",
    "    c = 3\n",
    "    for D in tqdm(boke_datas):\n",
    "        tmp = list()\n",
    "        for W in D[\"tokenized_boke\"]:\n",
    "            try:\n",
    "                index_to_index[W]\n",
    "            except:\n",
    "                index_to_index[W] = c\n",
    "                c += 1\n",
    "            tmp.append(index_to_index[W])\n",
    "        D[\"tokenized_boke\"] = [1] + tmp + [2]\n",
    "\n",
    "    index_to_word = {\n",
    "        V: tokenizer.decode([K]) for K, V in index_to_index.items()\n",
    "    }\n",
    "    index_to_word[0] = \"<PAD>\"\n",
    "    index_to_word[1] = \"<START>\"\n",
    "    index_to_word[2] = \"<END>\"\n",
    "\n",
    "    #\n",
    "    train_boke_datas, test_boke_datas = train_test_split(boke_datas, test_size = 0.01)\n",
    "\n",
    "    with open(f\"{RESULT_DIR}train_boke_datas.json\", \"w\") as f:\n",
    "        json.dump(train_boke_datas, f)\n",
    "    with open(f\"{RESULT_DIR}test_boke_datas.json\", \"w\") as f:\n",
    "        json.dump(test_boke_datas, f)\n",
    "    with open(f\"{RESULT_DIR}index_to_word.json\", \"w\") as f:\n",
    "        json.dump(index_to_word, f)\n",
    "\n",
    "else:\n",
    "    with open(f\"{RESULT_DIR}train_boke_datas.json\", \"r\") as f:\n",
    "        train_boke_datas = json.load(f)\n",
    "    with open(f\"{RESULT_DIR}test_boke_datas.json\", \"r\") as f:\n",
    "        test_boke_datas = json.load(f)\n",
    "    with open(f\"{RESULT_DIR}index_to_word.json\", \"r\") as f:\n",
    "        index_to_word = json.load(f)\n",
    "\n",
    "    image_numbers = [D[\"image_number\"] for D in train_boke_datas] + [D[\"image_number\"] for D in test_boke_datas]\n",
    "    image_numbers = list(set(image_numbers))\n",
    "\n",
    "print(f\"学習に用いる大喜利の数: {len(train_boke_datas)}\\n\", \n",
    "      f\"検証に用いる大喜利の数: {len(test_boke_datas)}\\n\",\n",
    "      f\"使用する画像の数: {len(image_numbers)}\\n\",\n",
    "      f\"単語の種類: {len(index_to_word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像のデータローダを作る関数\n",
    "def make_image_dataloader(image_numbers, num_workers = 4):\n",
    "    # 画像の前処理\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    class LoadImageDataset(Dataset):\n",
    "        def __init__(self, image_numbers):\n",
    "            \"\"\"\n",
    "                image_numbers: 画像の番号からなるリスト\n",
    "            \"\"\"\n",
    "            self.image_numbers = image_numbers\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.image_numbers)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = Image.open(f\"{IMAGE_DIR}{self.image_numbers[idx]}.jpg\").convert(\"RGB\")\n",
    "\n",
    "            return image, self.image_numbers[idx]\n",
    "    \n",
    "    def collate_fn_tf(batch):\n",
    "        images = torch.stack([transform(B[0]) for B in batch])\n",
    "        image_numbers = [B[1] for B in batch]\n",
    "\n",
    "        return images, image_numbers\n",
    "\n",
    "    print(f\"num data: {len(image_numbers)}\")\n",
    "\n",
    "    dataset = LoadImageDataset(image_numbers)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size = BATCH_SIZE, \n",
    "        num_workers = num_workers, \n",
    "        collate_fn = collate_fn_tf\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244286/244286 [00:00<00:00, 358195.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# 画像を特徴量に変換する\n",
    "tmp = list()\n",
    "for IN in tqdm(image_numbers):\n",
    "    if os.path.exists(f\"{IMAGE_FEATURE_DIR}{IN}.npy\"):\n",
    "        continue\n",
    "    tmp.append(IN)\n",
    "\n",
    "if len(tmp) != 0:\n",
    "    image_dataloader = make_image_dataloader(tmp, num_workers = NUM_WORKERS)\n",
    "\n",
    "    # resnet152\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = models.resnet152(pretrained = True)\n",
    "    model = torch.nn.Sequential(*list(model.children())[:-1] + [nn.Flatten()])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for Is, INs in tqdm(image_dataloader):\n",
    "        Is = Is.to(device)\n",
    "        features = model(Is).detach().cpu().numpy()\n",
    "\n",
    "        for F, IN in zip(features, INs):\n",
    "            np.save(f\"{IMAGE_FEATURE_DIR}{IN}\", F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大喜利生成AIの学習用データローダを作る関数\n",
    "def make_dataloader(boke_datas, max_sentence_length, num_workers = 4):\n",
    "    \"\"\"\n",
    "        boke_datas: {\"image_number\":画像のお題番号 ,\"tokenized_boke\":トークナイズされた大喜利}からなるリスト\n",
    "        max_sentence_length: 学習データの最大単語数(<START>, <END>トークンを含まない)\n",
    "        num_workers: データローダが使用するCPUのスレッド数\n",
    "    \"\"\"\n",
    "    class SentenceGeneratorDataset(Dataset):\n",
    "        def __init__(self, image_file_numbers, sentences, teacher_signals):\n",
    "            \"\"\"\n",
    "                image_file_numbers: 画像の番号からなるリスト\n",
    "                sentences: 入力文章からなるリスト\n",
    "                teacher_signals: 教師信号からなるリスト\n",
    "            \"\"\"\n",
    "            if len(image_file_numbers) != len(sentences) and len(teacher_signals) != len(sentences):\n",
    "                raise ValueError(\"データリストの長さが一致しません\")\n",
    "\n",
    "            self.image_file_numbers = image_file_numbers\n",
    "            self.sentences = sentences\n",
    "            self.teacher_signals = teacher_signals\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.teacher_signals)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image_feature = np.load(f\"{IMAGE_FEATURE_DIR}{self.image_file_numbers[idx]}.npy\")\n",
    "            sentence = self.sentences[idx]\n",
    "            teacher_signal = self.teacher_signals[idx]\n",
    "\n",
    "            return image_feature, sentence, teacher_signal\n",
    "\n",
    "    def collate_fn_tf(batch):\n",
    "        image_features = torch.tensor(np.array([B[0] for B in batch]))\n",
    "        sentences = torch.tensor(np.array([B[1] for B in batch]))\n",
    "        teacher_signals = torch.tensor(np.array([B[2] for B in batch]))\n",
    "\n",
    "        return image_features, sentences, teacher_signals\n",
    "\n",
    "    image_file_numbers = list()\n",
    "    sentences = list()\n",
    "    teacher_signals = list()\n",
    "\n",
    "    for D in tqdm(boke_datas):\n",
    "        image_file_numbers.append(D[\"image_number\"])\n",
    "        tmp = D[\"tokenized_boke\"] + [0] * (2 + max_sentence_length - len(D[\"tokenized_boke\"]))\n",
    "        sentences.append(tmp[:-1])\n",
    "        teacher_signals.append(tmp[1:])\n",
    "\n",
    "    dataset = SentenceGeneratorDataset(image_file_numbers, sentences, teacher_signals)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size = BATCH_SIZE, \n",
    "        num_workers = num_workers, \n",
    "        collate_fn = collate_fn_tf\n",
    "    )\n",
    "\n",
    "    print(f\"num data: {len(teacher_signals)}\")\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大喜利生成モデルのクラス\n",
    "class BokeGeneratorModel(nn.Module):\n",
    "    def __init__(self, num_word, image_feature_dim, sentence_length, feature_dim = 1024):\n",
    "        \"\"\"\n",
    "            num_word: 学習に用いる単語の総数\n",
    "            image_feature_dim: 画像の特徴量の次元数\n",
    "            sentence_length: 入力する文章の単語数\n",
    "            feature_dim: 特徴量次元数\n",
    "        \"\"\"\n",
    "        super(BokeGeneratorModel, self).__init__()\n",
    "        self.num_word = num_word\n",
    "        self.image_feature_dim = image_feature_dim\n",
    "        self.sentence_length = sentence_length\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(image_feature_dim, feature_dim)\n",
    "        self.embedding = nn.Embedding(num_word, feature_dim, padding_idx = 0)\n",
    "        self.lstm = nn.LSTM(input_size = feature_dim, hidden_size = feature_dim, \n",
    "                            batch_first = True)\n",
    "        self.fc2 = nn.Linear(feature_dim + feature_dim, 2 * feature_dim)\n",
    "        self.fc3 = nn.Linear(2 * feature_dim, 2 * feature_dim)\n",
    "        self.fc4 = nn.Linear(2 * feature_dim, num_word)\n",
    "    \n",
    "    # LSTMの初期値は0で，画像の特徴量と文章の特徴量を全結合層の前で結合する\n",
    "    def forward(self, image_features, sentences):\n",
    "        \"\"\"\n",
    "            image_features: 画像の特徴量\n",
    "            sentences: 入力する文章\n",
    "        \"\"\"\n",
    "        x1 = F.leaky_relu(self.fc1(image_features))\n",
    "        x1 = x1.unsqueeze(1).repeat(1, self.sentence_length, 1)\n",
    "\n",
    "        x2 = self.embedding(sentences)\n",
    "        x2, _ = self.lstm(x2)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim = -1)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章生成の精度を計算する関数\n",
    "def calculate_accuracy(teacher_signals, outputs):\n",
    "    \"\"\"\n",
    "        teacher_signals: 教師信号\n",
    "        outputs: モデルの出力\n",
    "    \"\"\"\n",
    "    _, predicted_words = outputs.max(dim = -1)\n",
    "    # パディングに対して精度を計算しない\n",
    "    mask = (teacher_signals != 0)\n",
    "    correct = ((predicted_words == teacher_signals) & mask).sum().item()\n",
    "    total = mask.sum().item()\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return accuracy\n",
    "\n",
    "# 1イテレーション学習する関数\n",
    "def train_step(model, optimizer, batch_data, batch_labels):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(*batch_data)\n",
    "    # パディングに対して損失を計算しない\n",
    "    loss = F.cross_entropy(outputs.view(-1, outputs.size(-1)), batch_labels.view(-1),\n",
    "                           ignore_index = 0)\n",
    "    accuracy = calculate_accuracy(batch_labels, F.softmax(outputs, dim = -1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), accuracy\n",
    "\n",
    "# 1イテレーション検証する関数\n",
    "def evaluate(model, batch_data, batch_labels):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(*batch_data)\n",
    "        loss = F.cross_entropy(outputs.view(-1, outputs.size(-1)), batch_labels.view(-1),\n",
    "                               ignore_index = 0)\n",
    "        accuracy = calculate_accuracy(batch_labels, F.softmax(outputs, dim = -1))\n",
    "    return loss.item(), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2030920 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2030920/2030920 [00:07<00:00, 259863.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data: 2030920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20515/20515 [00:00<00:00, 455825.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data: 20515\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = make_dataloader(train_boke_datas, max_sentence_length = MAX_SENTENCE_LENGTH, num_workers = NUM_WORKERS)\n",
    "test_dataloader = make_dataloader(test_boke_datas, max_sentence_length = MAX_SENTENCE_LENGTH, num_workers = NUM_WORKERS)\n",
    "\n",
    "model = BokeGeneratorModel(num_word = len(index_to_word), \n",
    "                           image_feature_dim = 2048, \n",
    "                           sentence_length = MAX_SENTENCE_LENGTH + 1, \n",
    "                           feature_dim = FEATURE_DIM)\n",
    "\n",
    "# 学習履歴がある場合，途中から再開する\n",
    "if os.path.exists(f\"{RESULT_DIR}history.json\"):\n",
    "    with open(f\"{RESULT_DIR}history.json\", \"r\") as f:\n",
    "        a = json.load(f)\n",
    "        train_loss_history = a[\"train_loss\"]\n",
    "        train_accuracy_history = a[\"train_accuracy\"]\n",
    "        test_loss_history = a[\"test_loss\"]\n",
    "        test_accuracy_history = a[\"test_accuracy\"]\n",
    "    model.load_state_dict(torch.load(f\"{RESULT_DIR}model_{len(train_loss_history):03}.pth\"))\n",
    "    SATRT_EPOCH = len(train_loss_history)\n",
    "else:\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    SATRT_EPOCH = 0\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25:   0%|          | 0/3967 [00:01<?, ?it/s, train_loss=9.72, train_accuracy=0]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=8.6, test_accuracy=0.0825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25, Train Loss: 0.0025, Train Accuracy: 0.0000, Test Loss: 0.2096, Test Accuracy: 0.0020\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=8.39, train_accuracy=0.0796]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=26.2, test_accuracy=0.0825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/25, Train Loss: 0.0021, Train Accuracy: 0.0000, Test Loss: 0.6396, Test Accuracy: 0.0020\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=24, train_accuracy=0.0796]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=7.85, test_accuracy=0.0825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/25, Train Loss: 0.0061, Train Accuracy: 0.0000, Test Loss: 0.1914, Test Accuracy: 0.0020\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=6.73, train_accuracy=0.0796]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=8.44, test_accuracy=0.0246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/25, Train Loss: 0.0017, Train Accuracy: 0.0000, Test Loss: 0.2059, Test Accuracy: 0.0006\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=7.91, train_accuracy=0.0319]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=8.76, test_accuracy=0.0337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/25, Train Loss: 0.0020, Train Accuracy: 0.0000, Test Loss: 0.2137, Test Accuracy: 0.0008\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=8.35, train_accuracy=0.0526]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=8.56, test_accuracy=0.0329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/25, Train Loss: 0.0021, Train Accuracy: 0.0000, Test Loss: 0.2087, Test Accuracy: 0.0008\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=7.97, train_accuracy=0.0521]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=8.4, test_accuracy=0.0311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/25, Train Loss: 0.0020, Train Accuracy: 0.0000, Test Loss: 0.2050, Test Accuracy: 0.0008\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=7.18, train_accuracy=0.0479]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=10.5, test_accuracy=0.0308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/25, Train Loss: 0.0018, Train Accuracy: 0.0000, Test Loss: 0.2564, Test Accuracy: 0.0008\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=7.85, train_accuracy=0.0465]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=9.59, test_accuracy=0.0396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/25, Train Loss: 0.0020, Train Accuracy: 0.0000, Test Loss: 0.2339, Test Accuracy: 0.0010\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=7.06, train_accuracy=0.0488]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=8.74, test_accuracy=0.0543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/25, Train Loss: 0.0018, Train Accuracy: 0.0000, Test Loss: 0.2131, Test Accuracy: 0.0013\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=6.62, train_accuracy=0.0667]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=8.6, test_accuracy=0.0855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/25, Train Loss: 0.0017, Train Accuracy: 0.0000, Test Loss: 0.2097, Test Accuracy: 0.0021\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25:   0%|          | 0/3967 [00:00<?, ?it/s, train_loss=6.55, train_accuracy=0.0919]\n",
      "Evaluating:   0%|          | 0/41 [00:00<?, ?it/s, test_loss=9.02, test_accuracy=0.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/25, Train Loss: 0.0017, Train Accuracy: 0.0000, Test Loss: 0.2200, Test Accuracy: 0.0022\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25:   0%|          | 0/3967 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "\n",
    "    # train\n",
    "    train_loss_obj = 0.0\n",
    "    train_accuracy_obj = 0.0\n",
    "    model.train()\n",
    "    pb = tqdm(train_dataloader, desc = f\"Epoch {epoch+1}/{EPOCH}\")\n",
    "    \n",
    "    for image_features, sentences, teacher_signals in pb:\n",
    "        image_features = image_features.to(device)\n",
    "        sentences = sentences.to(device)\n",
    "        teacher_signals = teacher_signals.to(device)\n",
    "        \n",
    "        loss, accuracy = train_step(model, optimizer, (image_features, sentences), teacher_signals)\n",
    "        train_loss_obj += loss\n",
    "        train_accuracy_obj += accuracy\n",
    "        pb.set_postfix({\"train_loss\": train_loss_obj / (pb.n + 1), \"train_accuracy\": train_accuracy_obj / (pb.n + 1)})\n",
    "        break\n",
    "    train_loss = train_loss_obj / len(train_dataloader)\n",
    "    train_accuracy = train_accuracy_obj / len(train_dataloader)\n",
    "\n",
    "    # test\n",
    "    test_loss_obj = 0.0\n",
    "    test_accuracy_obj = 0.0\n",
    "    model.eval()\n",
    "    pb = tqdm(test_dataloader, desc = \"Evaluating\")\n",
    "\n",
    "    for image_features, sentences, teacher_signals in pb:\n",
    "        image_features = image_features.to(device)\n",
    "        sentences = sentences.to(device)\n",
    "        teacher_signals = teacher_signals.to(device)\n",
    "\n",
    "        loss, accuracy = evaluate(model, (image_features, sentences), teacher_signals)\n",
    "        test_loss_obj += loss\n",
    "        test_accuracy_obj += accuracy\n",
    "        pb.set_postfix({\"test_loss\": test_loss_obj / (pb.n + 1), \"test_accuracy\": test_accuracy_obj / (pb.n + 1)})\n",
    "        break\n",
    "    test_loss = test_loss_obj / len(test_dataloader)\n",
    "    test_accuracy = test_accuracy_obj / len(test_dataloader)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{EPOCH}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_accuracy_history.append(test_accuracy)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{RESULT_DIR}model_{len(train_loss_history):03}.pth\")\n",
    "    if os.path.exists(f\"{RESULT_DIR}model_{len(train_loss_history) - 1:03}.pth\"):\n",
    "        os.remove(f\"{RESULT_DIR}model_{len(train_loss_history) - 1:03}.pth\")\n",
    "\n",
    "    # 学習精度を更新した場合、重みを保存\n",
    "    if max(train_accuracy_history) == train_accuracy:\n",
    "        torch.save(model.state_dict(), f\"{RESULT_DIR}best_model.pth\")\n",
    "    \n",
    "    # 学習結果を保存\n",
    "    with open(f\"{RESULT_DIR}history.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"train_loss\": train_loss_history,\n",
    "            \"train_accuracy\": train_accuracy_history,\n",
    "            \"test_loss\": test_loss_history,\n",
    "            \"test_accuracy\": test_accuracy_history\n",
    "        }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果を描画\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(train_loss_history, label = \"train\")\n",
    "ax.plot(test_loss_history, label = \"test\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(train_accuracy_history, label = \"train\")\n",
    "ax.plot(test_accuracy_history, label = \"test\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "fig.savefig(f\"{RESULT_DIR}history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大喜利生成AI\n",
    "class NeuralJokingMachine:\n",
    "    def __init__(self, weight_path, index_to_word, sentence_length, feature_dim = 512):\n",
    "        \"\"\"\n",
    "            weight_path: 大喜利適合判定モデルの学習済みの重みのパス\n",
    "            index_to_word: 単語のID: 単語の辞書(0:<PAD>, 1:<START>, 2:<END>)\n",
    "            sentence_length: 入力する文章の単語数\n",
    "            feature_dim: 特徴量次元数\n",
    "        \"\"\"\n",
    "        self.index_to_word = index_to_word\n",
    "        self.sentence_length = sentence_length\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.boke_generate_model = BokeGeneratorModel(\n",
    "                                        num_word = len(index_to_word), \n",
    "                                        image_feature_dim = 2048, \n",
    "                                        sentence_length = sentence_length, \n",
    "                                        feature_dim = feature_dim)\n",
    "        self.boke_generate_model.load_state_dict(torch.load(weight_path))\n",
    "        self.boke_generate_model.to(self.device)\n",
    "        self.boke_generate_model.eval()\n",
    "\n",
    "        self.resnet152 = models.resnet152(pretrained = True)\n",
    "        self.resnet152 = torch.nn.Sequential(*list(self.resnet152.children())[:-1] + [nn.Flatten()])\n",
    "        self.resnet152 = self.resnet152.to(self.device)\n",
    "        self.resnet152.eval()\n",
    "\n",
    "        # 画像の前処理\n",
    "        self.image_preprocesser = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, image_path, argmax = False, top_k = 5):\n",
    "        \"\"\"\n",
    "            image_path: 大喜利を生成したい画像のパス\n",
    "            argmax: Trueなら最大確率の単語を選ぶ, FalseならTop-Kサンプリングを行う\n",
    "            top_k: Top-Kサンプリング時に考慮する単語の数\n",
    "        \"\"\"\n",
    "        image = Image.open(image_path)\n",
    "        preprocessed_image = self.image_preprocesser(image).to(self.device)\n",
    "        image_feature = self.resnet152( preprocessed_image.unsqueeze(0) ) # (1, 2048)\n",
    "        \n",
    "        generated_text = [1] # <START>トークン\n",
    "        for i in range(1, self.sentence_length):\n",
    "            tmp = generated_text + [0] * (self.sentence_length - i) # Padding\n",
    "            tmp = torch.Tensor(np.array(tmp)).unsqueeze(0).to(self.device).to(dtype=torch.int32) # (1, sentence_length)\n",
    "            pred = self.boke_generate_model(image_feature, tmp) # (1, sentence_length, num_word)\n",
    "            target_pred = pred[0][i - 1]\n",
    "\n",
    "            if argmax:\n",
    "                # 最大確率の単語を選ぶ\n",
    "                chosen_id = torch.argmax(target_pred).item()\n",
    "            else:\n",
    "                # Top-Kサンプリング\n",
    "                top_k_probs, top_k_indices = torch.topk(target_pred, top_k)\n",
    "                top_k_probs = torch.nn.functional.softmax(top_k_probs, dim = -1)\n",
    "                chosen_id = np.random.choice(top_k_indices.detach().cpu().numpy(), \n",
    "                                             p = top_k_probs.detach().cpu().numpy())\n",
    "            \n",
    "            generated_text.append(chosen_id)\n",
    "            if chosen_id == 2:\n",
    "                break\n",
    "        \n",
    "        generated_sentence = \"\"\n",
    "        for I in generated_text[1:-1]:\n",
    "            generated_sentence += self.index_to_word[I]\n",
    "        return generated_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
