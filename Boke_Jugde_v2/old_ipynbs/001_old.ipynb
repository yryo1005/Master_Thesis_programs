{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 現実写真のみ、文字なし、固有名詞全部なし、キャプション、ほかの画像の大喜利"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIENCE_NUMBER = \"001\"\n",
    "\n",
    "# PCによって変更する\n",
    "NUM_WORKERS = 16\n",
    "\n",
    "USE_UNREAL_IMAGE = False\n",
    "USE_WORD_IMAGE = False\n",
    "USE_UNIQUE_NOUN_BOKE = False\n",
    "USE_CAPTION = True\n",
    "USE_MISS_BOKE = True\n",
    "\n",
    "RESULT_DIR = f\"../../results/Boke_Judge/{EXPERIENCE_NUMBER}/\"\n",
    "if not os.path.exists(\"../../results/Boke_Judge/\"):\n",
    "    os.mkdir(\"../../results/Boke_Judge/\")\n",
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.mkdir(RESULT_DIR)\n",
    "\n",
    "\n",
    "EPOCH = 25\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "DATA_DIR = \"../../datas/boke_data_assemble/\"\n",
    "CLIP_IMAGE_FEATURE_DIR = \"../../datas/encoded/clip_image_feature/\"\n",
    "CLIP_SENTENCE_FEATURE_DIR = \"../../datas/encoded/clip_sentence_feature/\"\n",
    "LUKE_SENTENCE_FEATURE_DIR = \"../../datas/encoded/luke_sentence_feature/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{RESULT_DIR}test_caption_datas.json\"):\n",
    "    \n",
    "    boke_datas = list()\n",
    "    caption_datas = list()\n",
    "\n",
    "    max_num_boke = 0\n",
    "    for JP in tqdm(os.listdir(DATA_DIR)):\n",
    "        N = int(JP.split(\".\")[0])\n",
    "\n",
    "        with open(f\"{DATA_DIR}{JP}\", \"r\") as f:\n",
    "            a = json.load(f)\n",
    "\n",
    "        image_information = a[\"image_information\"]\n",
    "        is_photographic_probability = image_information[\"is_photographic_probability\"]\n",
    "        ja_caption = image_information[\"ja_caption\"]\n",
    "        ocr = image_information[\"ocr\"]\n",
    "\n",
    "        # 現実写真以外を除去\n",
    "        if not USE_UNREAL_IMAGE:\n",
    "            if is_photographic_probability < 0.8: continue\n",
    "            \n",
    "        # 文字のある画像を除去\n",
    "        if not USE_WORD_IMAGE:\n",
    "            if len(ocr) != 0: continue\n",
    "\n",
    "        bokes = a[\"bokes\"]\n",
    "\n",
    "        max_num_boke = max(max_num_boke, len(a[\"bokes\"]))\n",
    "        for i, B in enumerate(bokes):\n",
    "\n",
    "            # 固有名詞を含む大喜利を除去\n",
    "            if not USE_UNIQUE_NOUN_BOKE:\n",
    "                if len(B[\"unique_nouns\"]) != 0: continue\n",
    "\n",
    "            boke_datas.append({\n",
    "                \"boke_number\": i,\n",
    "                \"image_number\": N\n",
    "            })\n",
    "\n",
    "        caption_datas.append({\n",
    "            \"caption_number\": N,\n",
    "            \"image_number\": N\n",
    "        })\n",
    "\n",
    "    len(boke_datas), len(caption_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{RESULT_DIR}test_caption_datas.json\"):\n",
    "    \n",
    "    train_boke_datas, test_boke_datas = train_test_split(boke_datas, test_size = 0.01)\n",
    "    train_caption_datas, test_caption_datas = train_test_split(caption_datas, test_size = 0.01)\n",
    "\n",
    "    with open(f\"{RESULT_DIR}train_boke_datas.json\", \"w\") as f:\n",
    "        json.dump(train_boke_datas, f)\n",
    "    with open(f\"{RESULT_DIR}train_caption_datas.json\", \"w\") as f:\n",
    "        json.dump(train_caption_datas, f)\n",
    "\n",
    "    with open(f\"{RESULT_DIR}test_boke_datas.json\", \"w\") as f:\n",
    "        json.dump(test_boke_datas, f)\n",
    "    with open(f\"{RESULT_DIR}test_caption_datas.json\", \"w\") as f:\n",
    "        json.dump(test_caption_datas, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2297194, 251799, 23204, 2544)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"{RESULT_DIR}train_boke_datas.json\", \"r\") as f:\n",
    "    train_boke_datas = json.load(f)\n",
    "with open(f\"{RESULT_DIR}train_caption_datas.json\", \"r\") as f:\n",
    "    train_caption_datas = json.load(f)\n",
    "\n",
    "with open(f\"{RESULT_DIR}test_boke_datas.json\", \"r\") as f:\n",
    "    test_boke_datas = json.load(f)\n",
    "with open(f\"{RESULT_DIR}test_caption_datas.json\", \"r\") as f:\n",
    "    test_caption_datas = json.load(f)\n",
    "\n",
    "len(train_boke_datas), len(train_caption_datas), len(test_boke_datas), len(test_caption_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2297194it [00:02, 1131216.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data: 4846187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23204it [00:00, 87923.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data: 48952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((64, 512), (64, 512), (64, 768), (64,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_dataloader(boke_datas, caption_datas, \n",
    "                    use_caption = False, use_miss_boke = False, \n",
    "                    num_workers = 4):\n",
    "    class LoadNpyDataset(Dataset):\n",
    "        def __init__(self, image_file_paths, sentence_file_paths, teacher_signals):\n",
    "            if len(image_file_paths) != len(sentence_file_paths) and len(sentence_file_paths) != len(teacher_signals):\n",
    "                raise ValueError(\"データリストの長さが一致しません\")\n",
    "\n",
    "            self.image_file_paths = image_file_paths\n",
    "            self.sentence_file_paths = sentence_file_paths\n",
    "            self.teacher_signals = teacher_signals\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.teacher_signals)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            clip_image_feature = np.load(f\"{CLIP_IMAGE_FEATURE_DIR}{self.image_file_paths[idx]}.npy\")\n",
    "            clip_sentence_feature = np.load(f\"{CLIP_SENTENCE_FEATURE_DIR}{self.sentence_file_paths[idx]}.npy\")\n",
    "            luke_sentence_feature = np.load(f\"{LUKE_SENTENCE_FEATURE_DIR}{self.sentence_file_paths[idx]}.npy\")\n",
    "            teacher_signal = self.teacher_signals[idx]\n",
    "\n",
    "            return clip_image_feature, clip_sentence_feature, luke_sentence_feature, teacher_signal\n",
    "\n",
    "    def collate_fn_tf(batch):\n",
    "        clip_image_features = np.array([B[0] for B in batch])\n",
    "        clip_sentence_features = np.array([B[1] for B in batch])\n",
    "        luke_sentence_features = np.array([B[2] for B in batch])\n",
    "        teacher_signals = np.array([float(B[3]) for B in batch])\n",
    "        \n",
    "        return clip_image_features, clip_sentence_features, luke_sentence_features, teacher_signals\n",
    "\n",
    "    #\n",
    "    image_file_numbers = list()\n",
    "    sentence_file_numbers = list()\n",
    "    teacher_signals = list()\n",
    "\n",
    "    for D in boke_datas:\n",
    "        image_file_numbers.append(D[\"image_number\"])\n",
    "        sentence_file_numbers.append(f'boke/{D[\"image_number\"]}/{D[\"boke_number\"]}')\n",
    "        teacher_signals.append(1)\n",
    "\n",
    "    if use_caption:\n",
    "        for D in caption_datas:\n",
    "            image_file_numbers.append(D[\"image_number\"])\n",
    "            sentence_file_numbers.append(f'caption/{D[\"image_number\"]}')\n",
    "            teacher_signals.append(0)\n",
    "    \n",
    "    if use_miss_boke:\n",
    "        miss_boke_datas = list()\n",
    "        tmp_idx = np.random.randint(0, len(boke_datas), size = (len(boke_datas), ))\n",
    "        for i, idx in tqdm(enumerate(tmp_idx)):\n",
    "            \n",
    "            while boke_datas[idx][\"image_number\"] == boke_datas[i][\"image_number\"]:\n",
    "                idx = np.random.randint(0, len(boke_datas))\n",
    "\n",
    "            miss_boke_datas.append({\n",
    "                \"boke_path\": f'boke/{boke_datas[idx][\"image_number\"]}/{boke_datas[idx][\"boke_number\"]}',\n",
    "                \"image_number\": boke_datas[i][\"image_number\"]\n",
    "            })\n",
    "        \n",
    "        for D in miss_boke_datas:\n",
    "            image_file_numbers.append(D[\"image_number\"])\n",
    "            sentence_file_numbers.append(D[\"boke_path\"])\n",
    "            teacher_signals.append(0)\n",
    "    \n",
    "    print(f\"num data: {len(teacher_signals)}\")\n",
    "\n",
    "    tmp = list(zip(image_file_numbers, sentence_file_numbers, teacher_signals))\n",
    "    np.random.shuffle(tmp)\n",
    "    image_file_numbers, sentence_file_numbers, teacher_signals = zip(*tmp)\n",
    "\n",
    "    dataset = LoadNpyDataset(image_file_numbers, sentence_file_numbers, teacher_signals)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size = BATCH_SIZE, \n",
    "        num_workers = num_workers, \n",
    "        collate_fn = collate_fn_tf\n",
    "    )\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "train_dataloader = make_dataloader(train_boke_datas, train_caption_datas, \n",
    "                                   use_caption = USE_CAPTION, use_miss_boke = USE_MISS_BOKE, \n",
    "                                   num_workers = NUM_WORKERS)\n",
    "test_dataloader = make_dataloader(test_boke_datas, test_caption_datas, \n",
    "                                  use_caption = USE_CAPTION, use_miss_boke = USE_MISS_BOKE, \n",
    "                                  num_workers = NUM_WORKERS)\n",
    "\n",
    "#\n",
    "CIF, CSF, LSF, TS = next(iter(train_dataloader))\n",
    "CIF.shape, CSF.shape, LSF.shape, TS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (fc1): Linear(in_features=1792, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (output_layer): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cif_dim, csf_dim, lsf_dim):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.cif_dim = cif_dim\n",
    "        self.csf_dim = csf_dim\n",
    "        self.lsf_dim = lsf_dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(cif_dim + csf_dim + lsf_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 1024)\n",
    "        self.output_layer = nn.Linear(1024, 1)\n",
    "        \n",
    "    def forward(self, cif, csf, lsf):\n",
    "\n",
    "        x = torch.cat([cif, csf, lsf], dim=1)\n",
    "\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "\n",
    "        output = torch.sigmoid(self.output_layer(x))\n",
    "        return output\n",
    "\n",
    "model = CustomModel(CIF.shape[1], CSF.shape[1], LSF.shape[1])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num data: 2297194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25:   2%|▏         | 645/35894 [00:11<10:42, 54.87it/s, train_loss=0.00371, train_accuracy=1]    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9d7a8f79cd09>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Epoch {epoch+1}/{EPOCH}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mCIF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTS\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mCIF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCIF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCIF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Colab_20241111/lib/python3.10/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Colab_20241111/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
      "\u001b[0;32m~/.conda/envs/Colab_20241111/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Colab_20241111/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Colab_20241111/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Colab_20241111/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Colab_20241111/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Colab_20241111/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Colab_20241111/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/Colab_20241111/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_step(model, optimizer, batch_data, batch_labels):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(*batch_data).float()\n",
    "    loss = nn.BCELoss()(outputs, batch_labels.float())\n",
    "    accuracy = ((outputs > 0.5).float() == batch_labels).float().mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "def evaluate(model, batch_data, batch_labels):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(*batch_data)\n",
    "        loss = nn.BCELoss()(outputs, batch_labels)\n",
    "        accuracy = ((outputs > 0.5).float() == batch_labels).float().mean()\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "test_loss_history = []\n",
    "test_accuracy_history = []\n",
    "\n",
    "model = CustomModel(CIF.shape[1], CSF.shape[1], LSF.shape[1])\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 0.0001)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # train\n",
    "    train_loss_obj = 0.0\n",
    "    train_accuracy_obj = 0.0\n",
    "    model.train()\n",
    "    train_dataloader = make_dataloader(train_boke_datas, train_caption_datas)\n",
    "    pb = tqdm(train_dataloader, desc = f\"Epoch {epoch+1}/{EPOCH}\")\n",
    "    \n",
    "    for CIF, CSF, LSF, TS in pb:\n",
    "        CIF, CSF, LSF, TS = torch.tensor(CIF), torch.tensor(CSF), torch.tensor(LSF), torch.tensor(TS)\n",
    "        batch_data = (CIF, CSF, LSF)\n",
    "        batch_labels = TS.unsqueeze(1)\n",
    "        \n",
    "        loss, accuracy = train_step(model, optimizer, batch_data, batch_labels)\n",
    "        train_loss_obj += loss\n",
    "        train_accuracy_obj += accuracy\n",
    "        pb.set_postfix({\"train_loss\": train_loss_obj / (pb.n + 1), \"train_accuracy\": train_accuracy_obj / (pb.n + 1)})\n",
    "\n",
    "    train_loss = train_loss_obj / len(train_dataloader)\n",
    "    train_accuracy = train_accuracy_obj / len(train_dataloader)\n",
    "\n",
    "    # test\n",
    "    test_loss_obj = 0.0\n",
    "    test_accuracy_obj = 0.0\n",
    "    model.eval()\n",
    "    test_dataloader = make_dataloader(test_boke_datas, test_caption_datas)\n",
    "    pb = tqdm(test_dataloader, desc = \"Evaluating\")\n",
    "\n",
    "    for CIF, CSF, LSF, TS in pb:\n",
    "        CIF, CSF, LSF, TS = torch.tensor(CIF).float(), torch.tensor(CSF).float(), torch.tensor(LSF).float(), torch.tensor(TS).float()\n",
    "        batch_data = (CIF, CSF, LSF)\n",
    "        batch_labels = TS.unsqueeze(1).float()\n",
    "        \n",
    "        loss, accuracy = evaluate(model, batch_data, batch_labels)\n",
    "        test_loss_obj += loss\n",
    "        test_accuracy_obj += accuracy\n",
    "        pb.set_postfix({\"test_loss\": test_loss_obj / (pb.n + 1), \"test_accuracy\": test_accuracy_obj / (pb.n + 1)})\n",
    "\n",
    "    test_loss = test_loss_obj / len(test_dataloader)\n",
    "    test_accuracy = test_accuracy_obj / len(test_dataloader)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}/{EPOCH}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    test_loss_history.append(test_loss)\n",
    "    test_accuracy_history.append(test_accuracy)\n",
    "\n",
    "    if max(test_accuracy_history) == test_accuracy:\n",
    "        torch.save(model.state_dict(), f\"{RESULT_DIR}best_model_weights.pth\")\n",
    "\n",
    "with open(f\"{RESULT_DIR}history.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"train_loss\": train_loss_history,\n",
    "        \"train_accuracy\": train_accuracy_history,\n",
    "        \"test_loss\": test_loss_history,\n",
    "        \"test_accuracy\": test_accuracy_history\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(train_loss_history, label = \"train\")\n",
    "ax.plot(test_loss_history, label = \"test\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(train_accuracy_history, label = \"train\")\n",
    "ax.plot(test_accuracy_history, label = \"test\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Colab_20241111",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
